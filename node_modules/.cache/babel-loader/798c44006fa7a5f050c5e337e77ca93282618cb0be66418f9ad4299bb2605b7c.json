{"ast":null,"code":"/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util } from '@tensorflow/tfjs-core';\nimport { getMainHeaderString as main } from './webgpu_program';\nimport { computeDispatch, flatDispatchLayout } from './webgpu_util';\nexport class ReduceProgram {\n  constructor(reduceInfo, reduceType, maxComputeWorkgroupSizeX) {\n    this.variableNames = ['x'];\n    this.uniforms = 'reduceSize : i32,';\n    this.size = true;\n    this.inputShape = [reduceInfo.batchSize, reduceInfo.inSize];\n    const [outputShape] = backend_util.computeOutAndReduceShapes(this.inputShape, [1]);\n    this.outputShape = outputShape.length === 0 ? [1] : outputShape;\n    // If reduceSize |reduceInfo.inSize| is very large, the I/O accessing will\n    // become the bottleneck. Increasing workgroupSize can reduce the times of\n    // accessing global memory. The threshold value is just to make sure the\n    // reduceSize is large enough for a bigger workgroupSize.\n    if (reduceInfo.inSize >= 32768 && maxComputeWorkgroupSizeX >= 512) {\n      this.workgroupSize = [512, 1, 1];\n    } else if (reduceInfo.inSize >= 4096) {\n      this.workgroupSize = [256, 1, 1];\n    } else {\n      this.workgroupSize = [64, 1, 1];\n    }\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    // A work group only outputs a data, so we transfer [1, 1, 1] to compute\n    // dispatch size.\n    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, [1, 1, 1]);\n    this.reduceType = reduceType;\n    this.shaderKey = `reduce_${reduceType}`;\n  }\n  getUserCode() {\n    let reduceOp = ``;\n    let initValue = '0.0';\n    const workgroupSizeX = this.workgroupSize[0];\n    if (this.reduceType === 'min' || this.reduceType === 'max') {\n      reduceOp = `\n         if (isnan(candidate)) {\n          bestValue = uniforms.NAN;\n         } else if (!isnan(bestValue) && candidate ${this.reduceType === 'min' ? '<' : '>'} bestValue)\n           {  bestValue = candidate; }`;\n      initValue = 'f32(x[offset])';\n    } else if (this.reduceType === 'sum' || this.reduceType === 'mean') {\n      reduceOp = ' bestValue = bestValue + candidate; ';\n    } else if (this.reduceType === 'prod') {\n      reduceOp = ' bestValue = bestValue * candidate; ';\n      initValue = '1.0';\n    } else if (this.reduceType === 'all') {\n      reduceOp = ' bestValue = f32(bestValue >= 1.0 && candidate >= 1.0); ';\n      initValue = '1.0';\n    } else if (this.reduceType === 'any') {\n      reduceOp = ' bestValue = f32(bestValue >= 1.0 || candidate >= 1.0); ';\n      initValue = '0.0';\n    }\n    const outputSnippet = this.reduceType === 'mean' ?\n    // tslint:disable-next-line:max-line-length\n    `setOutputAtIndex(outputIndex, bestValue / f32(uniforms.reduceSize));` : `setOutputAtIndex(outputIndex, bestValue);`;\n    const sharedMemorySnippet = `\n         var<workgroup> xBestValues : array<f32, ${workgroupSizeX}>;\n       `;\n    const userCode = `\n       fn DIV_CEIL(a : u32, b : u32) -> u32 {\n        return ((a - 1u) / b + 1u);\n       }\n\n       ${sharedMemorySnippet}\n       fn getOffset(outputIndex : i32) -> i32 {\n         let outputCoords = getCoordsFromIndex(outputIndex);\n         let offset = ${this.outputShape.length === 1 ? 'outputCoords' : 'outputCoords[0]'} * uniforms.reduceSize;\n          return offset;\n       }\n       ${main('index')} {\n         let outputIndex = index / ${workgroupSizeX};\n         let offset = getOffset(outputIndex);\n         var bestValue = ${initValue};\n         let Length = uniforms.reduceSize;\n         let WorkPerThread = DIV_CEIL(u32(Length), ${workgroupSizeX}u);\n         for (var k = i32(localId.x); k < Length && outputIndex < uniforms.size;\n             k = k + ${workgroupSizeX}) {\n           let candidate = f32(x[offset + k]);\n           ${reduceOp}\n         }\n         xBestValues[localId.x] = bestValue;\n         workgroupBarrier();\n\n         var reduceSize = min(u32(Length), ${workgroupSizeX}u);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (localId.x < currentSize) {\n            let candidate = xBestValues[localId.x + interval];\n            ${reduceOp}\n            xBestValues[localId.x] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (localId.x == 0u && outputIndex < uniforms.size) {\n          ${outputSnippet}\n        }\n       }\n     `;\n    return userCode;\n  }\n}","map":{"version":3,"names":["backend_util","getMainHeaderString","main","computeDispatch","flatDispatchLayout","ReduceProgram","constructor","reduceInfo","reduceType","maxComputeWorkgroupSizeX","variableNames","uniforms","size","inputShape","batchSize","inSize","outputShape","computeOutAndReduceShapes","length","workgroupSize","dispatchLayout","dispatch","shaderKey","getUserCode","reduceOp","initValue","workgroupSizeX","outputSnippet","sharedMemorySnippet","userCode"],"sources":["/Users/jesvinblazegmail.com/PycharmProjects/tfjs-backend-webgpu/src/reduce_webgpu.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util} from '@tensorflow/tfjs-core';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, flatDispatchLayout} from './webgpu_util';\n\nexport class ReduceProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[]};\n  dispatch: [number, number, number];\n  workgroupSize: [number, number, number];\n  variableNames = ['x'];\n  uniforms = 'reduceSize : i32,';\n  reduceType: 'all'|'any'|'max'|'mean'|'min'|'prod'|'sum';\n  inputShape: number[];\n  size = true;\n\n  constructor(\n      reduceInfo: backend_util.ReduceInfo,\n      reduceType: 'all'|'any'|'max'|'mean'|'min'|'prod'|'sum',\n      maxComputeWorkgroupSizeX: number) {\n    this.inputShape = [reduceInfo.batchSize, reduceInfo.inSize];\n    const [outputShape, ] =\n        backend_util.computeOutAndReduceShapes(this.inputShape, [1]);\n    this.outputShape = outputShape.length === 0 ? [1] : outputShape;\n    // If reduceSize |reduceInfo.inSize| is very large, the I/O accessing will\n    // become the bottleneck. Increasing workgroupSize can reduce the times of\n    // accessing global memory. The threshold value is just to make sure the\n    // reduceSize is large enough for a bigger workgroupSize.\n    if (reduceInfo.inSize >= 32768 && maxComputeWorkgroupSizeX >= 512) {\n      this.workgroupSize = [512, 1, 1];\n    } else if (reduceInfo.inSize >= 4096) {\n      this.workgroupSize = [256, 1, 1];\n    } else {\n      this.workgroupSize = [64, 1, 1];\n    }\n    this.dispatchLayout = flatDispatchLayout(this.outputShape);\n    // A work group only outputs a data, so we transfer [1, 1, 1] to compute\n    // dispatch size.\n    this.dispatch =\n        computeDispatch(this.dispatchLayout, this.outputShape, [1, 1, 1]);\n\n    this.reduceType = reduceType;\n    this.shaderKey = `reduce_${reduceType}`;\n  }\n\n  getUserCode(): string {\n    let reduceOp = ``;\n    let initValue = '0.0';\n    const workgroupSizeX = this.workgroupSize[0];\n    if (this.reduceType === 'min' || this.reduceType === 'max') {\n      reduceOp = `\n         if (isnan(candidate)) {\n          bestValue = uniforms.NAN;\n         } else if (!isnan(bestValue) && candidate ${\n          this.reduceType === 'min' ? '<' : '>'} bestValue)\n           {  bestValue = candidate; }`;\n      initValue = 'f32(x[offset])';\n    } else if (this.reduceType === 'sum' || this.reduceType === 'mean') {\n      reduceOp = ' bestValue = bestValue + candidate; ';\n    } else if (this.reduceType === 'prod') {\n      reduceOp = ' bestValue = bestValue * candidate; ';\n      initValue = '1.0';\n    } else if (this.reduceType === 'all') {\n      reduceOp = ' bestValue = f32(bestValue >= 1.0 && candidate >= 1.0); ';\n      initValue = '1.0';\n    } else if (this.reduceType === 'any') {\n      reduceOp = ' bestValue = f32(bestValue >= 1.0 || candidate >= 1.0); ';\n      initValue = '0.0';\n    }\n\n    const outputSnippet = this.reduceType === 'mean' ?\n        // tslint:disable-next-line:max-line-length\n        `setOutputAtIndex(outputIndex, bestValue / f32(uniforms.reduceSize));` :\n        `setOutputAtIndex(outputIndex, bestValue);`;\n\n    const sharedMemorySnippet = `\n         var<workgroup> xBestValues : array<f32, ${workgroupSizeX}>;\n       `;\n\n    const userCode = `\n       fn DIV_CEIL(a : u32, b : u32) -> u32 {\n        return ((a - 1u) / b + 1u);\n       }\n\n       ${sharedMemorySnippet}\n       fn getOffset(outputIndex : i32) -> i32 {\n         let outputCoords = getCoordsFromIndex(outputIndex);\n         let offset = ${\n        this.outputShape.length === 1 ?\n            'outputCoords' :\n            'outputCoords[0]'} * uniforms.reduceSize;\n          return offset;\n       }\n       ${main('index')} {\n         let outputIndex = index / ${workgroupSizeX};\n         let offset = getOffset(outputIndex);\n         var bestValue = ${initValue};\n         let Length = uniforms.reduceSize;\n         let WorkPerThread = DIV_CEIL(u32(Length), ${workgroupSizeX}u);\n         for (var k = i32(localId.x); k < Length && outputIndex < uniforms.size;\n             k = k + ${workgroupSizeX}) {\n           let candidate = f32(x[offset + k]);\n           ${reduceOp}\n         }\n         xBestValues[localId.x] = bestValue;\n         workgroupBarrier();\n\n         var reduceSize = min(u32(Length), ${workgroupSizeX}u);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (localId.x < currentSize) {\n            let candidate = xBestValues[localId.x + interval];\n            ${reduceOp}\n            xBestValues[localId.x] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (localId.x == 0u && outputIndex < uniforms.size) {\n          ${outputSnippet}\n        }\n       }\n     `;\n    return userCode;\n  }\n}\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,YAAY,QAAO,uBAAuB;AAClD,SAAQC,mBAAmB,IAAIC,IAAI,QAAsB,kBAAkB;AAC3E,SAAQC,eAAe,EAAEC,kBAAkB,QAAO,eAAe;AAEjE,OAAM,MAAOC,aAAa;EAYxBC,YACIC,UAAmC,EACnCC,UAAuD,EACvDC,wBAAgC;IATpC,KAAAC,aAAa,GAAG,CAAC,GAAG,CAAC;IACrB,KAAAC,QAAQ,GAAG,mBAAmB;IAG9B,KAAAC,IAAI,GAAG,IAAI;IAMT,IAAI,CAACC,UAAU,GAAG,CAACN,UAAU,CAACO,SAAS,EAAEP,UAAU,CAACQ,MAAM,CAAC;IAC3D,MAAM,CAACC,WAAW,CAAG,GACjBhB,YAAY,CAACiB,yBAAyB,CAAC,IAAI,CAACJ,UAAU,EAAE,CAAC,CAAC,CAAC,CAAC;IAChE,IAAI,CAACG,WAAW,GAAGA,WAAW,CAACE,MAAM,KAAK,CAAC,GAAG,CAAC,CAAC,CAAC,GAAGF,WAAW;IAC/D;IACA;IACA;IACA;IACA,IAAIT,UAAU,CAACQ,MAAM,IAAI,KAAK,IAAIN,wBAAwB,IAAI,GAAG,EAAE;MACjE,IAAI,CAACU,aAAa,GAAG,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC;KACjC,MAAM,IAAIZ,UAAU,CAACQ,MAAM,IAAI,IAAI,EAAE;MACpC,IAAI,CAACI,aAAa,GAAG,CAAC,GAAG,EAAE,CAAC,EAAE,CAAC,CAAC;KACjC,MAAM;MACL,IAAI,CAACA,aAAa,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC;;IAEjC,IAAI,CAACC,cAAc,GAAGhB,kBAAkB,CAAC,IAAI,CAACY,WAAW,CAAC;IAC1D;IACA;IACA,IAAI,CAACK,QAAQ,GACTlB,eAAe,CAAC,IAAI,CAACiB,cAAc,EAAE,IAAI,CAACJ,WAAW,EAAE,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC,CAAC;IAErE,IAAI,CAACR,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAACc,SAAS,GAAG,UAAUd,UAAU,EAAE;EACzC;EAEAe,WAAWA,CAAA;IACT,IAAIC,QAAQ,GAAG,EAAE;IACjB,IAAIC,SAAS,GAAG,KAAK;IACrB,MAAMC,cAAc,GAAG,IAAI,CAACP,aAAa,CAAC,CAAC,CAAC;IAC5C,IAAI,IAAI,CAACX,UAAU,KAAK,KAAK,IAAI,IAAI,CAACA,UAAU,KAAK,KAAK,EAAE;MAC1DgB,QAAQ,GAAG;;;qDAIP,IAAI,CAAChB,UAAU,KAAK,KAAK,GAAG,GAAG,GAAG,GAAG;uCACR;MACjCiB,SAAS,GAAG,gBAAgB;KAC7B,MAAM,IAAI,IAAI,CAACjB,UAAU,KAAK,KAAK,IAAI,IAAI,CAACA,UAAU,KAAK,MAAM,EAAE;MAClEgB,QAAQ,GAAG,sCAAsC;KAClD,MAAM,IAAI,IAAI,CAAChB,UAAU,KAAK,MAAM,EAAE;MACrCgB,QAAQ,GAAG,sCAAsC;MACjDC,SAAS,GAAG,KAAK;KAClB,MAAM,IAAI,IAAI,CAACjB,UAAU,KAAK,KAAK,EAAE;MACpCgB,QAAQ,GAAG,0DAA0D;MACrEC,SAAS,GAAG,KAAK;KAClB,MAAM,IAAI,IAAI,CAACjB,UAAU,KAAK,KAAK,EAAE;MACpCgB,QAAQ,GAAG,0DAA0D;MACrEC,SAAS,GAAG,KAAK;;IAGnB,MAAME,aAAa,GAAG,IAAI,CAACnB,UAAU,KAAK,MAAM;IAC5C;IACA,sEAAsE,GACtE,2CAA2C;IAE/C,MAAMoB,mBAAmB,GAAG;mDACmBF,cAAc;QACzD;IAEJ,MAAMG,QAAQ,GAAG;;;;;SAKZD,mBAAmB;;;wBAIpB,IAAI,CAACZ,WAAW,CAACE,MAAM,KAAK,CAAC,GACzB,cAAc,GACd,iBAAiB;;;SAGpBhB,IAAI,CAAC,OAAO,CAAC;qCACewB,cAAc;;2BAExBD,SAAS;;qDAEiBC,cAAc;;uBAE5CA,cAAc;;aAExBF,QAAQ;;;;;6CAKwBE,cAAc;;;;;;cAM7CF,QAAQ;;;;;;;;YAQVG,aAAa;;;MAGnB;IACF,OAAOE,QAAQ;EACjB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}