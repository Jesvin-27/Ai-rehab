{"ast":null,"code":"/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, util } from '@tensorflow/tfjs-core';\nimport { ConcatProgram } from '../concat_webgpu';\nimport { concatImplCPU } from '../kernel_utils/shared';\nimport { complex } from './Complex';\nimport { imag } from './Imag';\nimport { real } from './Real';\nimport { reshape } from './Reshape';\nexport function concatImpl(inputs, axis, backend) {\n  const dtype = inputs[0].dtype;\n  if (dtype === 'complex64') {\n    const reals = inputs.map(t => real({\n      inputs: {\n        input: t\n      },\n      backend\n    }));\n    const imags = inputs.map(t => imag({\n      inputs: {\n        input: t\n      },\n      backend\n    }));\n    const realConcated = concatImpl(reals, axis, backend);\n    const imagConcated = concatImpl(imags, axis, backend);\n    const result = complex({\n      inputs: {\n        real: realConcated,\n        imag: imagConcated\n      },\n      backend\n    });\n    reals.forEach(r => backend.disposeData(r.dataId));\n    imags.forEach(i => backend.disposeData(i.dataId));\n    backend.disposeData(realConcated.dataId);\n    backend.disposeData(imagConcated.dataId);\n    return result;\n  }\n  let runOnCpu = backend.shouldExecuteOnCPU(inputs);\n  // Run on cpu if dtype is string. For string, the backend represents it\n  // as Uint8Array[], where each Uint8Array is a character. Given that the\n  // computation is only on the outer array, uploading the whole data onto\n  // gpu is wasteful. Also, currently webgpu doesn't have a design to\n  // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we\n  // just run the kernel on cpu if dtype is string.\n  if (dtype === 'string') {\n    runOnCpu = true;\n  }\n  if (runOnCpu) {\n    // Any concat of n-dimensional tensors across any axis can be reduced to\n    // a concatenation of two-dimensional tensors across the axis 1 by first\n    // partitioning the axes of the original tensors into those less than the\n    // axis to be concatenated and the rest. Then reshape the tensors\n    // into a two-dimensional tensor by collapsing these two sets of axes and\n    // concatenate the resulting matrices across the axis 1, finally reshaping\n    // the result to have the proper shape.\n    const tensors2D = inputs.map(t => {\n      const innerSize = util.sizeFromShape(t.shape.slice(axis));\n      const shape = [-1, innerSize];\n      return reshape({\n        inputs: {\n          x: t\n        },\n        backend,\n        attrs: {\n          shape\n        }\n      });\n    });\n    const inputsValShapes = tensors2D.map(t => {\n      return {\n        vals: backend.readSync(t.dataId),\n        shape: t.shape\n      };\n    });\n    // Concats 2d tensors along axis=1.\n    const outShape = backend_util.computeOutShape(tensors2D.map(t => t.shape), 1 /* axis */);\n    const simplyConcat = tensors2D[0].shape[0] === 1;\n    const outVals = concatImplCPU(inputsValShapes, outShape, dtype, simplyConcat);\n    const finalOutShape = backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n    const outInfo = backend.makeTensorInfo(finalOutShape, dtype, outVals);\n    tensors2D.forEach(t => backend.disposeData(t.dataId));\n    return outInfo;\n  }\n  // There is a storage buffer limitation in compute stage, one for output so\n  // the maximum for input is limits.maxStorageBuffersPerShaderStage - 1\n  const maxInputNum = backend.device.limits.maxStorageBuffersPerShaderStage - 1;\n  if (inputs.length > maxInputNum) {\n    const reducedInputs = [];\n    for (let i = 0; i < inputs.length; i += maxInputNum) {\n      const subArray = inputs.slice(i, i + maxInputNum);\n      reducedInputs.push(concatImpl(subArray, axis, backend));\n    }\n    const result = concatImpl(reducedInputs, axis, backend);\n    for (const i of reducedInputs) {\n      backend.disposeData(i.dataId);\n    }\n    return result;\n  }\n  const {\n    tensors2D,\n    outShape\n  } = computeTensors2D(inputs, axis, backend);\n  const shapes = tensors2D.map(t => t.shape);\n  const program = new ConcatProgram(shapes);\n  const uniformData = [];\n  const offsets = new Array(shapes.length - 1);\n  if (offsets.length > 0) {\n    offsets[0] = shapes[0][1];\n    uniformData.push({\n      type: 'int32',\n      data: [offsets[0]]\n    });\n    for (let i = 1; i < offsets.length; i++) {\n      offsets[i] = offsets[i - 1] + shapes[i][1];\n      uniformData.push({\n        type: 'int32',\n        data: [offsets[i]]\n      });\n    }\n  }\n  const res = backend.runWebGPUProgram(program, tensors2D, tensors2D[0].dtype, uniformData);\n  tensors2D.forEach(r => backend.disposeData(r.dataId));\n  const reshapedResult = reshape({\n    inputs: {\n      x: res\n    },\n    backend,\n    attrs: {\n      shape: outShape\n    }\n  });\n  backend.disposeData(res.dataId);\n  return reshapedResult;\n}\nfunction computeTensors2D(inputs, axis, backend) {\n  const outShape = backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n  const tensors2D = inputs.map(t => reshape({\n    inputs: {\n      x: t\n    },\n    backend,\n    attrs: {\n      shape: [util.sizeFromShape(t.shape.slice(0, axis)), util.sizeFromShape(t.shape.slice(axis))]\n    }\n  }));\n  return {\n    tensors2D,\n    outShape\n  };\n}","map":{"version":3,"names":["backend_util","util","ConcatProgram","concatImplCPU","complex","imag","real","reshape","concatImpl","inputs","axis","backend","dtype","reals","map","t","input","imags","realConcated","imagConcated","result","forEach","r","disposeData","dataId","i","runOnCpu","shouldExecuteOnCPU","tensors2D","innerSize","sizeFromShape","shape","slice","x","attrs","inputsValShapes","vals","readSync","outShape","computeOutShape","simplyConcat","outVals","finalOutShape","outInfo","makeTensorInfo","maxInputNum","device","limits","maxStorageBuffersPerShaderStage","length","reducedInputs","subArray","push","computeTensors2D","shapes","program","uniformData","offsets","Array","type","data","res","runWebGPUProgram","reshapedResult"],"sources":["/Users/jesvinblazegmail.com/PycharmProjects/tfjs-backend-webgpu/src/kernels/Concat_impl.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, ConcatInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {ConcatProgram} from '../concat_webgpu';\nimport {concatImplCPU} from '../kernel_utils/shared';\n\nimport {complex} from './Complex';\nimport {imag} from './Imag';\nimport {real} from './Real';\nimport {reshape} from './Reshape';\n\nexport function concatImpl(\n    inputs: ConcatInputs, axis: number, backend: WebGPUBackend): TensorInfo {\n  const dtype = inputs[0].dtype;\n  if (dtype === 'complex64') {\n    const reals = inputs.map((t) => real({inputs: {input: t}, backend}));\n    const imags = inputs.map((t) => imag({inputs: {input: t}, backend}));\n\n    const realConcated = concatImpl(reals, axis, backend);\n    const imagConcated = concatImpl(imags, axis, backend);\n\n    const result =\n        complex({inputs: {real: realConcated, imag: imagConcated}, backend});\n\n    reals.forEach(r => backend.disposeData(r.dataId));\n    imags.forEach(i => backend.disposeData(i.dataId));\n    backend.disposeData(realConcated.dataId);\n    backend.disposeData(imagConcated.dataId);\n\n    return result;\n  }\n\n  let runOnCpu = backend.shouldExecuteOnCPU(inputs);\n\n  // Run on cpu if dtype is string. For string, the backend represents it\n  // as Uint8Array[], where each Uint8Array is a character. Given that the\n  // computation is only on the outer array, uploading the whole data onto\n  // gpu is wasteful. Also, currently webgpu doesn't have a design to\n  // upload and retrieve Uint8Array[] between cpu and gpu. Therefore, we\n  // just run the kernel on cpu if dtype is string.\n  if (dtype === 'string') {\n    runOnCpu = true;\n  }\n\n  if (runOnCpu) {\n    // Any concat of n-dimensional tensors across any axis can be reduced to\n    // a concatenation of two-dimensional tensors across the axis 1 by first\n    // partitioning the axes of the original tensors into those less than the\n    // axis to be concatenated and the rest. Then reshape the tensors\n    // into a two-dimensional tensor by collapsing these two sets of axes and\n    // concatenate the resulting matrices across the axis 1, finally reshaping\n    // the result to have the proper shape.\n    const tensors2D = inputs.map(t => {\n      const innerSize = util.sizeFromShape(t.shape.slice(axis));\n      const shape = [-1, innerSize];\n      return reshape({inputs: {x: t}, backend, attrs: {shape}});\n    });\n\n    const inputsValShapes = tensors2D.map(t => {\n      return {vals: backend.readSync(t.dataId), shape: t.shape};\n    });\n\n    // Concats 2d tensors along axis=1.\n    const outShape =\n        backend_util.computeOutShape(tensors2D.map(t => t.shape), 1 /* axis */);\n    const simplyConcat = tensors2D[0].shape[0] === 1;\n    const outVals =\n        concatImplCPU(inputsValShapes, outShape, dtype, simplyConcat);\n\n    const finalOutShape =\n        backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n\n    const outInfo = backend.makeTensorInfo(finalOutShape, dtype, outVals);\n\n    tensors2D.forEach(t => backend.disposeData(t.dataId));\n\n    return outInfo;\n  }\n\n  // There is a storage buffer limitation in compute stage, one for output so\n  // the maximum for input is limits.maxStorageBuffersPerShaderStage - 1\n  const maxInputNum = backend.device.limits.maxStorageBuffersPerShaderStage - 1;\n  if (inputs.length > maxInputNum) {\n    const reducedInputs = [];\n    for (let i = 0; i < inputs.length; i += maxInputNum) {\n      const subArray = inputs.slice(i, i + maxInputNum);\n      reducedInputs.push(concatImpl(subArray, axis, backend));\n    }\n    const result = concatImpl(reducedInputs, axis, backend);\n\n    for (const i of reducedInputs) {\n      backend.disposeData(i.dataId);\n    }\n\n    return result;\n  }\n\n  const {tensors2D, outShape} = computeTensors2D(inputs, axis, backend);\n  const shapes = (tensors2D).map(t => t.shape as [number, number]);\n  const program = new ConcatProgram(shapes);\n\n  const uniformData: Array<{type: string; data: number[]}> = [];\n  const offsets: number[] = new Array(shapes.length - 1);\n  if (offsets.length > 0) {\n    offsets[0] = shapes[0][1];\n    uniformData.push({type: 'int32', data: [offsets[0]]});\n    for (let i = 1; i < offsets.length; i++) {\n      offsets[i] = offsets[i - 1] + shapes[i][1];\n      uniformData.push({type: 'int32', data: [offsets[i]]});\n    }\n  }\n\n  const res = backend.runWebGPUProgram(\n      program, tensors2D, tensors2D[0].dtype, uniformData);\n  tensors2D.forEach(r => backend.disposeData(r.dataId));\n\n  const reshapedResult =\n      reshape({inputs: {x: res}, backend, attrs: {shape: outShape}});\n  backend.disposeData(res.dataId);\n  return reshapedResult;\n}\n\nfunction computeTensors2D(\n    inputs: ConcatInputs, axis: number, backend: WebGPUBackend) {\n  const outShape = backend_util.computeOutShape(inputs.map(t => t.shape), axis);\n  const tensors2D = inputs.map(t => reshape({\n                                 inputs: {x: t},\n                                 backend,\n                                 attrs: {\n                                   shape: [\n                                     util.sizeFromShape(t.shape.slice(0, axis)),\n                                     util.sizeFromShape(t.shape.slice(axis))\n                                   ]\n                                 }\n                               }));\n\n  return {tensors2D, outShape};\n}\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,YAAY,EAA4BC,IAAI,QAAO,uBAAuB;AAGlF,SAAQC,aAAa,QAAO,kBAAkB;AAC9C,SAAQC,aAAa,QAAO,wBAAwB;AAEpD,SAAQC,OAAO,QAAO,WAAW;AACjC,SAAQC,IAAI,QAAO,QAAQ;AAC3B,SAAQC,IAAI,QAAO,QAAQ;AAC3B,SAAQC,OAAO,QAAO,WAAW;AAEjC,OAAM,SAAUC,UAAUA,CACtBC,MAAoB,EAAEC,IAAY,EAAEC,OAAsB;EAC5D,MAAMC,KAAK,GAAGH,MAAM,CAAC,CAAC,CAAC,CAACG,KAAK;EAC7B,IAAIA,KAAK,KAAK,WAAW,EAAE;IACzB,MAAMC,KAAK,GAAGJ,MAAM,CAACK,GAAG,CAAEC,CAAC,IAAKT,IAAI,CAAC;MAACG,MAAM,EAAE;QAACO,KAAK,EAAED;MAAC,CAAC;MAAEJ;IAAO,CAAC,CAAC,CAAC;IACpE,MAAMM,KAAK,GAAGR,MAAM,CAACK,GAAG,CAAEC,CAAC,IAAKV,IAAI,CAAC;MAACI,MAAM,EAAE;QAACO,KAAK,EAAED;MAAC,CAAC;MAAEJ;IAAO,CAAC,CAAC,CAAC;IAEpE,MAAMO,YAAY,GAAGV,UAAU,CAACK,KAAK,EAAEH,IAAI,EAAEC,OAAO,CAAC;IACrD,MAAMQ,YAAY,GAAGX,UAAU,CAACS,KAAK,EAAEP,IAAI,EAAEC,OAAO,CAAC;IAErD,MAAMS,MAAM,GACRhB,OAAO,CAAC;MAACK,MAAM,EAAE;QAACH,IAAI,EAAEY,YAAY;QAAEb,IAAI,EAAEc;MAAY,CAAC;MAAER;IAAO,CAAC,CAAC;IAExEE,KAAK,CAACQ,OAAO,CAACC,CAAC,IAAIX,OAAO,CAACY,WAAW,CAACD,CAAC,CAACE,MAAM,CAAC,CAAC;IACjDP,KAAK,CAACI,OAAO,CAACI,CAAC,IAAId,OAAO,CAACY,WAAW,CAACE,CAAC,CAACD,MAAM,CAAC,CAAC;IACjDb,OAAO,CAACY,WAAW,CAACL,YAAY,CAACM,MAAM,CAAC;IACxCb,OAAO,CAACY,WAAW,CAACJ,YAAY,CAACK,MAAM,CAAC;IAExC,OAAOJ,MAAM;;EAGf,IAAIM,QAAQ,GAAGf,OAAO,CAACgB,kBAAkB,CAAClB,MAAM,CAAC;EAEjD;EACA;EACA;EACA;EACA;EACA;EACA,IAAIG,KAAK,KAAK,QAAQ,EAAE;IACtBc,QAAQ,GAAG,IAAI;;EAGjB,IAAIA,QAAQ,EAAE;IACZ;IACA;IACA;IACA;IACA;IACA;IACA;IACA,MAAME,SAAS,GAAGnB,MAAM,CAACK,GAAG,CAACC,CAAC,IAAG;MAC/B,MAAMc,SAAS,GAAG5B,IAAI,CAAC6B,aAAa,CAACf,CAAC,CAACgB,KAAK,CAACC,KAAK,CAACtB,IAAI,CAAC,CAAC;MACzD,MAAMqB,KAAK,GAAG,CAAC,CAAC,CAAC,EAAEF,SAAS,CAAC;MAC7B,OAAOtB,OAAO,CAAC;QAACE,MAAM,EAAE;UAACwB,CAAC,EAAElB;QAAC,CAAC;QAAEJ,OAAO;QAAEuB,KAAK,EAAE;UAACH;QAAK;MAAC,CAAC,CAAC;IAC3D,CAAC,CAAC;IAEF,MAAMI,eAAe,GAAGP,SAAS,CAACd,GAAG,CAACC,CAAC,IAAG;MACxC,OAAO;QAACqB,IAAI,EAAEzB,OAAO,CAAC0B,QAAQ,CAACtB,CAAC,CAACS,MAAM,CAAC;QAAEO,KAAK,EAAEhB,CAAC,CAACgB;MAAK,CAAC;IAC3D,CAAC,CAAC;IAEF;IACA,MAAMO,QAAQ,GACVtC,YAAY,CAACuC,eAAe,CAACX,SAAS,CAACd,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACgB,KAAK,CAAC,EAAE,CAAC,CAAC,UAAU,CAAC;IAC3E,MAAMS,YAAY,GAAGZ,SAAS,CAAC,CAAC,CAAC,CAACG,KAAK,CAAC,CAAC,CAAC,KAAK,CAAC;IAChD,MAAMU,OAAO,GACTtC,aAAa,CAACgC,eAAe,EAAEG,QAAQ,EAAE1B,KAAK,EAAE4B,YAAY,CAAC;IAEjE,MAAME,aAAa,GACf1C,YAAY,CAACuC,eAAe,CAAC9B,MAAM,CAACK,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACgB,KAAK,CAAC,EAAErB,IAAI,CAAC;IAEhE,MAAMiC,OAAO,GAAGhC,OAAO,CAACiC,cAAc,CAACF,aAAa,EAAE9B,KAAK,EAAE6B,OAAO,CAAC;IAErEb,SAAS,CAACP,OAAO,CAACN,CAAC,IAAIJ,OAAO,CAACY,WAAW,CAACR,CAAC,CAACS,MAAM,CAAC,CAAC;IAErD,OAAOmB,OAAO;;EAGhB;EACA;EACA,MAAME,WAAW,GAAGlC,OAAO,CAACmC,MAAM,CAACC,MAAM,CAACC,+BAA+B,GAAG,CAAC;EAC7E,IAAIvC,MAAM,CAACwC,MAAM,GAAGJ,WAAW,EAAE;IAC/B,MAAMK,aAAa,GAAG,EAAE;IACxB,KAAK,IAAIzB,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGhB,MAAM,CAACwC,MAAM,EAAExB,CAAC,IAAIoB,WAAW,EAAE;MACnD,MAAMM,QAAQ,GAAG1C,MAAM,CAACuB,KAAK,CAACP,CAAC,EAAEA,CAAC,GAAGoB,WAAW,CAAC;MACjDK,aAAa,CAACE,IAAI,CAAC5C,UAAU,CAAC2C,QAAQ,EAAEzC,IAAI,EAAEC,OAAO,CAAC,CAAC;;IAEzD,MAAMS,MAAM,GAAGZ,UAAU,CAAC0C,aAAa,EAAExC,IAAI,EAAEC,OAAO,CAAC;IAEvD,KAAK,MAAMc,CAAC,IAAIyB,aAAa,EAAE;MAC7BvC,OAAO,CAACY,WAAW,CAACE,CAAC,CAACD,MAAM,CAAC;;IAG/B,OAAOJ,MAAM;;EAGf,MAAM;IAACQ,SAAS;IAAEU;EAAQ,CAAC,GAAGe,gBAAgB,CAAC5C,MAAM,EAAEC,IAAI,EAAEC,OAAO,CAAC;EACrE,MAAM2C,MAAM,GAAI1B,SAAS,CAAEd,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACgB,KAAyB,CAAC;EAChE,MAAMwB,OAAO,GAAG,IAAIrD,aAAa,CAACoD,MAAM,CAAC;EAEzC,MAAME,WAAW,GAA0C,EAAE;EAC7D,MAAMC,OAAO,GAAa,IAAIC,KAAK,CAACJ,MAAM,CAACL,MAAM,GAAG,CAAC,CAAC;EACtD,IAAIQ,OAAO,CAACR,MAAM,GAAG,CAAC,EAAE;IACtBQ,OAAO,CAAC,CAAC,CAAC,GAAGH,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;IACzBE,WAAW,CAACJ,IAAI,CAAC;MAACO,IAAI,EAAE,OAAO;MAAEC,IAAI,EAAE,CAACH,OAAO,CAAC,CAAC,CAAC;IAAC,CAAC,CAAC;IACrD,KAAK,IAAIhC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGgC,OAAO,CAACR,MAAM,EAAExB,CAAC,EAAE,EAAE;MACvCgC,OAAO,CAAChC,CAAC,CAAC,GAAGgC,OAAO,CAAChC,CAAC,GAAG,CAAC,CAAC,GAAG6B,MAAM,CAAC7B,CAAC,CAAC,CAAC,CAAC,CAAC;MAC1C+B,WAAW,CAACJ,IAAI,CAAC;QAACO,IAAI,EAAE,OAAO;QAAEC,IAAI,EAAE,CAACH,OAAO,CAAChC,CAAC,CAAC;MAAC,CAAC,CAAC;;;EAIzD,MAAMoC,GAAG,GAAGlD,OAAO,CAACmD,gBAAgB,CAChCP,OAAO,EAAE3B,SAAS,EAAEA,SAAS,CAAC,CAAC,CAAC,CAAChB,KAAK,EAAE4C,WAAW,CAAC;EACxD5B,SAAS,CAACP,OAAO,CAACC,CAAC,IAAIX,OAAO,CAACY,WAAW,CAACD,CAAC,CAACE,MAAM,CAAC,CAAC;EAErD,MAAMuC,cAAc,GAChBxD,OAAO,CAAC;IAACE,MAAM,EAAE;MAACwB,CAAC,EAAE4B;IAAG,CAAC;IAAElD,OAAO;IAAEuB,KAAK,EAAE;MAACH,KAAK,EAAEO;IAAQ;EAAC,CAAC,CAAC;EAClE3B,OAAO,CAACY,WAAW,CAACsC,GAAG,CAACrC,MAAM,CAAC;EAC/B,OAAOuC,cAAc;AACvB;AAEA,SAASV,gBAAgBA,CACrB5C,MAAoB,EAAEC,IAAY,EAAEC,OAAsB;EAC5D,MAAM2B,QAAQ,GAAGtC,YAAY,CAACuC,eAAe,CAAC9B,MAAM,CAACK,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACgB,KAAK,CAAC,EAAErB,IAAI,CAAC;EAC7E,MAAMkB,SAAS,GAAGnB,MAAM,CAACK,GAAG,CAACC,CAAC,IAAIR,OAAO,CAAC;IACXE,MAAM,EAAE;MAACwB,CAAC,EAAElB;IAAC,CAAC;IACdJ,OAAO;IACPuB,KAAK,EAAE;MACLH,KAAK,EAAE,CACL9B,IAAI,CAAC6B,aAAa,CAACf,CAAC,CAACgB,KAAK,CAACC,KAAK,CAAC,CAAC,EAAEtB,IAAI,CAAC,CAAC,EAC1CT,IAAI,CAAC6B,aAAa,CAACf,CAAC,CAACgB,KAAK,CAACC,KAAK,CAACtB,IAAI,CAAC,CAAC;;GAG5C,CAAC,CAAC;EAEhC,OAAO;IAACkB,SAAS;IAAEU;EAAQ,CAAC;AAC9B","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}