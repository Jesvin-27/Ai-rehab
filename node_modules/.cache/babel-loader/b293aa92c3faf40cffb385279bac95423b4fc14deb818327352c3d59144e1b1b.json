{"ast":null,"code":"/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util } from '@tensorflow/tfjs-core';\nimport { CumProgram } from '../cum_webgpu';\nimport { identity } from './Identity';\nimport { transpose } from './Transpose';\nexport function cumImpl(op, x, backend, axis, exclusive, reverse) {\n  const xRank = x.shape.length;\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n  if (permutation != null) {\n    permutedX = transpose({\n      inputs: {\n        x\n      },\n      backend,\n      attrs: {\n        perm: permutation\n      }\n    });\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, xRank)[0];\n  if (permutedAxis !== xRank - 1) {\n    throw new Error(`WebGPU cumprod shader expects an inner-most axis=${x.shape.length - 1} ` + `but got axis=${axis}`);\n  }\n  const size = permutedX.shape[permutedAxis];\n  let result = identity({\n    inputs: {\n      x: permutedX\n    },\n    backend\n  });\n  // Use cum parallel algorithm, inspired by:\n  // https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda\n  // Note: although the algorithm is called sum, it works for any associtative\n  // operator with an identity.\n  for (let i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {\n    const program = new CumProgram(op, permutedX.shape, false, reverse);\n    const prevResult = result;\n    const uniformData = [{\n      type: 'float32',\n      data: [i]\n    }];\n    result = backend.runWebGPUProgram(program, [result], result.dtype, uniformData);\n    backend.disposeData(prevResult.dataId);\n  }\n  // For exclusive cum, shift the end result in the direction of product or sum\n  // and add 1 for product or 0 for sum to the front index.\n  if (exclusive) {\n    const program = new CumProgram(op, permutedX.shape, exclusive, reverse);\n    const prevResult = result;\n    const uniformData = [{\n      type: 'float32',\n      data: [0]\n    }];\n    result = backend.runWebGPUProgram(program, [result], result.dtype, uniformData);\n    backend.disposeData(prevResult.dataId);\n  }\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose({\n      inputs: {\n        x: result\n      },\n      backend,\n      attrs: {\n        perm: reversePermutation\n      }\n    });\n    backend.disposeData(result.dataId);\n    backend.disposeData(permutedX.dataId);\n    return reverseTransposedResult;\n  }\n  return result;\n}","map":{"version":3,"names":["backend_util","CumProgram","identity","transpose","cumImpl","op","x","backend","axis","exclusive","reverse","xRank","shape","length","permutation","getAxesPermutation","permutedX","inputs","attrs","perm","permutedAxis","getInnerMostAxes","Error","size","result","i","Math","ceil","log2","program","prevResult","uniformData","type","data","runWebGPUProgram","dtype","disposeData","dataId","reversePermutation","getUndoAxesPermutation","reverseTransposedResult"],"sources":["/Users/jesvinblazegmail.com/PycharmProjects/tfjs-backend-webgpu/src/kernels/Cum_impl.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {WebGPUBackend} from '../backend_webgpu';\nimport {CumOpType, CumProgram} from '../cum_webgpu';\n\nimport {identity} from './Identity';\nimport {transpose} from './Transpose';\n\nexport function cumImpl(\n    op: CumOpType, x: TensorInfo, backend: WebGPUBackend, axis: number,\n    exclusive: boolean, reverse: boolean): TensorInfo {\n  const xRank = x.shape.length;\n  const permutation = backend_util.getAxesPermutation([axis], xRank);\n  let permutedX = x;\n  if (permutation != null) {\n    permutedX = transpose({inputs: {x}, backend, attrs: {perm: permutation}});\n  }\n  const permutedAxis = backend_util.getInnerMostAxes(1, xRank)[0];\n\n  if (permutedAxis !== xRank - 1) {\n    throw new Error(\n        `WebGPU cumprod shader expects an inner-most axis=${\n            x.shape.length - 1} ` +\n        `but got axis=${axis}`);\n  }\n  const size = permutedX.shape[permutedAxis];\n  let result = identity({inputs: {x: permutedX}, backend});\n  // Use cum parallel algorithm, inspired by:\n  // https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda\n  // Note: although the algorithm is called sum, it works for any associtative\n  // operator with an identity.\n\n  for (let i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {\n    const program = new CumProgram(op, permutedX.shape, false, reverse);\n    const prevResult = result;\n    const uniformData = [{type: 'float32', data: [i]}];\n    result =\n        backend.runWebGPUProgram(program, [result], result.dtype, uniformData);\n    backend.disposeData(prevResult.dataId);\n  }\n  // For exclusive cum, shift the end result in the direction of product or sum\n  // and add 1 for product or 0 for sum to the front index.\n  if (exclusive) {\n    const program = new CumProgram(op, permutedX.shape, exclusive, reverse);\n    const prevResult = result;\n    const uniformData = [{type: 'float32', data: [0]}];\n    result =\n        backend.runWebGPUProgram(program, [result], result.dtype, uniformData);\n    backend.disposeData(prevResult.dataId);\n  }\n\n  if (permutation != null) {\n    const reversePermutation = backend_util.getUndoAxesPermutation(permutation);\n    const reverseTransposedResult = transpose(\n        {inputs: {x: result}, backend, attrs: {perm: reversePermutation}});\n\n    backend.disposeData(result.dataId);\n    backend.disposeData(permutedX.dataId);\n\n    return reverseTransposedResult;\n  }\n\n  return result;\n}\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,YAAY,QAAmB,uBAAuB;AAG9D,SAAmBC,UAAU,QAAO,eAAe;AAEnD,SAAQC,QAAQ,QAAO,YAAY;AACnC,SAAQC,SAAS,QAAO,aAAa;AAErC,OAAM,SAAUC,OAAOA,CACnBC,EAAa,EAAEC,CAAa,EAAEC,OAAsB,EAAEC,IAAY,EAClEC,SAAkB,EAAEC,OAAgB;EACtC,MAAMC,KAAK,GAAGL,CAAC,CAACM,KAAK,CAACC,MAAM;EAC5B,MAAMC,WAAW,GAAGd,YAAY,CAACe,kBAAkB,CAAC,CAACP,IAAI,CAAC,EAAEG,KAAK,CAAC;EAClE,IAAIK,SAAS,GAAGV,CAAC;EACjB,IAAIQ,WAAW,IAAI,IAAI,EAAE;IACvBE,SAAS,GAAGb,SAAS,CAAC;MAACc,MAAM,EAAE;QAACX;MAAC,CAAC;MAAEC,OAAO;MAAEW,KAAK,EAAE;QAACC,IAAI,EAAEL;MAAW;IAAC,CAAC,CAAC;;EAE3E,MAAMM,YAAY,GAAGpB,YAAY,CAACqB,gBAAgB,CAAC,CAAC,EAAEV,KAAK,CAAC,CAAC,CAAC,CAAC;EAE/D,IAAIS,YAAY,KAAKT,KAAK,GAAG,CAAC,EAAE;IAC9B,MAAM,IAAIW,KAAK,CACX,oDACIhB,CAAC,CAACM,KAAK,CAACC,MAAM,GAAG,CAAC,GAAG,GACzB,gBAAgBL,IAAI,EAAE,CAAC;;EAE7B,MAAMe,IAAI,GAAGP,SAAS,CAACJ,KAAK,CAACQ,YAAY,CAAC;EAC1C,IAAII,MAAM,GAAGtB,QAAQ,CAAC;IAACe,MAAM,EAAE;MAACX,CAAC,EAAEU;IAAS,CAAC;IAAET;EAAO,CAAC,CAAC;EACxD;EACA;EACA;EACA;EAEA,KAAK,IAAIkB,CAAC,GAAG,CAAC,EAAEA,CAAC,IAAIC,IAAI,CAACC,IAAI,CAACD,IAAI,CAACE,IAAI,CAACL,IAAI,CAAC,CAAC,GAAG,CAAC,EAAEE,CAAC,EAAE,EAAE;IACxD,MAAMI,OAAO,GAAG,IAAI5B,UAAU,CAACI,EAAE,EAAEW,SAAS,CAACJ,KAAK,EAAE,KAAK,EAAEF,OAAO,CAAC;IACnE,MAAMoB,UAAU,GAAGN,MAAM;IACzB,MAAMO,WAAW,GAAG,CAAC;MAACC,IAAI,EAAE,SAAS;MAAEC,IAAI,EAAE,CAACR,CAAC;IAAC,CAAC,CAAC;IAClDD,MAAM,GACFjB,OAAO,CAAC2B,gBAAgB,CAACL,OAAO,EAAE,CAACL,MAAM,CAAC,EAAEA,MAAM,CAACW,KAAK,EAAEJ,WAAW,CAAC;IAC1ExB,OAAO,CAAC6B,WAAW,CAACN,UAAU,CAACO,MAAM,CAAC;;EAExC;EACA;EACA,IAAI5B,SAAS,EAAE;IACb,MAAMoB,OAAO,GAAG,IAAI5B,UAAU,CAACI,EAAE,EAAEW,SAAS,CAACJ,KAAK,EAAEH,SAAS,EAAEC,OAAO,CAAC;IACvE,MAAMoB,UAAU,GAAGN,MAAM;IACzB,MAAMO,WAAW,GAAG,CAAC;MAACC,IAAI,EAAE,SAAS;MAAEC,IAAI,EAAE,CAAC,CAAC;IAAC,CAAC,CAAC;IAClDT,MAAM,GACFjB,OAAO,CAAC2B,gBAAgB,CAACL,OAAO,EAAE,CAACL,MAAM,CAAC,EAAEA,MAAM,CAACW,KAAK,EAAEJ,WAAW,CAAC;IAC1ExB,OAAO,CAAC6B,WAAW,CAACN,UAAU,CAACO,MAAM,CAAC;;EAGxC,IAAIvB,WAAW,IAAI,IAAI,EAAE;IACvB,MAAMwB,kBAAkB,GAAGtC,YAAY,CAACuC,sBAAsB,CAACzB,WAAW,CAAC;IAC3E,MAAM0B,uBAAuB,GAAGrC,SAAS,CACrC;MAACc,MAAM,EAAE;QAACX,CAAC,EAAEkB;MAAM,CAAC;MAAEjB,OAAO;MAAEW,KAAK,EAAE;QAACC,IAAI,EAAEmB;MAAkB;IAAC,CAAC,CAAC;IAEtE/B,OAAO,CAAC6B,WAAW,CAACZ,MAAM,CAACa,MAAM,CAAC;IAClC9B,OAAO,CAAC6B,WAAW,CAACpB,SAAS,CAACqB,MAAM,CAAC;IAErC,OAAOG,uBAAuB;;EAGhC,OAAOhB,MAAM;AACf","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}