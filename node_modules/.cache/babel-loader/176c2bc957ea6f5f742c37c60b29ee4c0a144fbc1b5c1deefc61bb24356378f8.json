{"ast":null,"code":"/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { activationFnSnippet } from './activation_util';\nimport { matMulReadWriteFnSource } from './matmul_packed_webgpu';\nimport { getMainHeaderString as main } from './webgpu_program';\nexport function makeMatMulSmallOutputSizeSource(workgroupSize) {\n  const tileAOuter = workgroupSize[1];\n  const tileBOuter = workgroupSize[0];\n  const tileInner = tileAOuter > tileBOuter ? tileAOuter : tileBOuter;\n  return `\n  var<workgroup> mm_Asub : array<array<f32, ${tileInner}>, ${tileAOuter}>;\n  var<workgroup> mm_Bsub : array<array<f32, ${tileBOuter}>, ${tileInner}>;\n\n  // If the output size is small for matrix multiplication, avoid to use vec4\n  // and handle some elements per thread to optimally utilize the ALU.\n  // Read data from global memory to registers firstly, then store them into\n  // shared memory, so it is instruction-Level parallelism for arithmetic\n  // operations and others handle IO operations between barrier api, makes ALU\n  // and load/store units work simultaneously, could improves the performance.\n  ${main()} {\n    let tileRow = i32(localId.y);\n    let tileCol = i32(localId.x);\n    let globalRow = i32(globalId.y);\n    let globalCol = i32(globalId.x);\n    let batch = i32(globalId.z);\n    let batchA = batch % uniforms.aShape[0];\n    let batchB = batch % uniforms.bShape[0];\n\n    // uniforms.dimInner should be greater than 0.\n    let numTiles = (uniforms.dimInner - 1) / ${tileInner} + 1;\n    var acc = 0.0;\n\n    var globalColA = tileCol;\n    var globalRowB = 0;\n    var regA = mm_readA(batchA, globalRow, globalColA);\n    var regB0 = mm_readB(batchB, globalRowB + 2 * tileRow, globalCol);\n    var regB1 = mm_readB(batchB, globalRowB + 2 * tileRow + 1, globalCol);\n    globalColA = globalColA + ${tileInner};\n    globalRowB = globalRowB + ${tileInner};\n\n    for (var t = 0; t < numTiles; t = t + 1) {\n      mm_Asub[tileRow][tileCol] = regA;\n      mm_Bsub[2 * tileRow][tileCol] = regB0;\n      mm_Bsub[2 * tileRow + 1][tileCol] = regB1;\n\n      workgroupBarrier();\n\n      regA = mm_readA(batchA, globalRow, globalColA);\n      regB0 = mm_readB(batchB, globalRowB + 2 * tileRow, globalCol);\n      regB1 = mm_readB(batchB, globalRowB + 2 * tileRow + 1, globalCol);\n      globalColA = globalColA + ${tileInner};\n      globalRowB = globalRowB + ${tileInner};\n\n      for (var k = 0; k < ${tileInner}; k = k + 1) {\n        acc = acc + mm_Asub[tileRow][k] * mm_Bsub[k][tileCol];\n      }\n      workgroupBarrier();\n    }\n\n    mm_write(batch, globalRow, globalCol, acc);\n  }\n  `;\n}\nexport class MatMulSmallOutputSizeProgram {\n  constructor(aShape, bShape, outputShape, transposeA = false, transposeB = false, bias = null, activation = null, preluActivationWeights = null) {\n    this.variableNames = ['A', 'B'];\n    this.uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n    this.workgroupSize = [16, 8, 1];\n    this.outputShape = outputShape;\n    this.dispatchLayout = {\n      x: [2],\n      y: [1],\n      z: [0]\n    };\n    this.dispatch = [Math.ceil(outputShape[2] / this.workgroupSize[0]), Math.ceil(outputShape[1] / this.workgroupSize[1]), outputShape[0]];\n    const addBias = bias != null;\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    if (hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n    this.transposeA = transposeA;\n    this.transposeB = transposeB;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n    this.shaderKey = `matMulSmallOutputSize_${this.activation}_${transposeA}_${transposeB}`;\n  }\n  getUserCode() {\n    const userCode = `\n      ${activationFnSnippet(this.activation, this.hasPreluActivationWeights)}\n      ${matMulReadWriteFnSource(this.addBias, this.activation, this.transposeA, this.transposeB)}\n      ${makeMatMulSmallOutputSizeSource(this.workgroupSize)}\n    `;\n    return userCode;\n  }\n}","map":{"version":3,"names":["activationFnSnippet","matMulReadWriteFnSource","getMainHeaderString","main","makeMatMulSmallOutputSizeSource","workgroupSize","tileAOuter","tileBOuter","tileInner","MatMulSmallOutputSizeProgram","constructor","aShape","bShape","outputShape","transposeA","transposeB","bias","activation","preluActivationWeights","variableNames","uniforms","dispatchLayout","x","y","z","dispatch","Math","ceil","addBias","push","hasPreluActivationWeights","shaderKey","getUserCode","userCode"],"sources":["/Users/jesvinblazegmail.com/PycharmProjects/tfjs-backend-webgpu/src/matmul_small_output_size_webgpu.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo} from '@tensorflow/tfjs-core';\nimport {activationFnSnippet} from './activation_util';\nimport {matMulReadWriteFnSource} from './matmul_packed_webgpu';\nimport {getMainHeaderString as main, WebGPUProgram} from './webgpu_program';\n\nexport function makeMatMulSmallOutputSizeSource(\n    workgroupSize: [number, number, number]): string {\n  const tileAOuter = workgroupSize[1];\n  const tileBOuter = workgroupSize[0];\n  const tileInner = tileAOuter > tileBOuter ? tileAOuter : tileBOuter;\n  return `\n  var<workgroup> mm_Asub : array<array<f32, ${tileInner}>, ${tileAOuter}>;\n  var<workgroup> mm_Bsub : array<array<f32, ${tileBOuter}>, ${tileInner}>;\n\n  // If the output size is small for matrix multiplication, avoid to use vec4\n  // and handle some elements per thread to optimally utilize the ALU.\n  // Read data from global memory to registers firstly, then store them into\n  // shared memory, so it is instruction-Level parallelism for arithmetic\n  // operations and others handle IO operations between barrier api, makes ALU\n  // and load/store units work simultaneously, could improves the performance.\n  ${main()} {\n    let tileRow = i32(localId.y);\n    let tileCol = i32(localId.x);\n    let globalRow = i32(globalId.y);\n    let globalCol = i32(globalId.x);\n    let batch = i32(globalId.z);\n    let batchA = batch % uniforms.aShape[0];\n    let batchB = batch % uniforms.bShape[0];\n\n    // uniforms.dimInner should be greater than 0.\n    let numTiles = (uniforms.dimInner - 1) / ${tileInner} + 1;\n    var acc = 0.0;\n\n    var globalColA = tileCol;\n    var globalRowB = 0;\n    var regA = mm_readA(batchA, globalRow, globalColA);\n    var regB0 = mm_readB(batchB, globalRowB + 2 * tileRow, globalCol);\n    var regB1 = mm_readB(batchB, globalRowB + 2 * tileRow + 1, globalCol);\n    globalColA = globalColA + ${tileInner};\n    globalRowB = globalRowB + ${tileInner};\n\n    for (var t = 0; t < numTiles; t = t + 1) {\n      mm_Asub[tileRow][tileCol] = regA;\n      mm_Bsub[2 * tileRow][tileCol] = regB0;\n      mm_Bsub[2 * tileRow + 1][tileCol] = regB1;\n\n      workgroupBarrier();\n\n      regA = mm_readA(batchA, globalRow, globalColA);\n      regB0 = mm_readB(batchB, globalRowB + 2 * tileRow, globalCol);\n      regB1 = mm_readB(batchB, globalRowB + 2 * tileRow + 1, globalCol);\n      globalColA = globalColA + ${tileInner};\n      globalRowB = globalRowB + ${tileInner};\n\n      for (var k = 0; k < ${tileInner}; k = k + 1) {\n        acc = acc + mm_Asub[tileRow][k] * mm_Bsub[k][tileCol];\n      }\n      workgroupBarrier();\n    }\n\n    mm_write(batch, globalRow, globalCol, acc);\n  }\n  `;\n}\n\nexport class MatMulSmallOutputSizeProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['A', 'B'];\n  uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n  workgroupSize: [number, number, number] = [16, 8, 1];\n  transposeA: boolean;\n  transposeB: boolean;\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivationWeights: boolean;\n\n  constructor(\n      aShape: [number, number, number], bShape: [number, number, number],\n      outputShape: [number, number, number], transposeA = false,\n      transposeB = false, bias: TensorInfo = null,\n      activation: backend_util.Activation = null,\n      preluActivationWeights: TensorInfo = null) {\n    this.outputShape = outputShape;\n\n    this.dispatchLayout = {x: [2], y: [1], z: [0]};\n    this.dispatch = [\n      Math.ceil(outputShape[2] / this.workgroupSize[0]),\n      Math.ceil(outputShape[1] / this.workgroupSize[1]), outputShape[0]\n    ];\n\n    const addBias = bias != null;\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    if (hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.transposeA = transposeA;\n    this.transposeB = transposeB;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n    this.shaderKey =\n        `matMulSmallOutputSize_${this.activation}_${transposeA}_${transposeB}`;\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${activationFnSnippet(this.activation, this.hasPreluActivationWeights)}\n      ${\n        matMulReadWriteFnSource(\n            this.addBias, this.activation, this.transposeA, this.transposeB)}\n      ${makeMatMulSmallOutputSizeSource(this.workgroupSize)}\n    `;\n    return userCode;\n  }\n}\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAkBA,SAAQA,mBAAmB,QAAO,mBAAmB;AACrD,SAAQC,uBAAuB,QAAO,wBAAwB;AAC9D,SAAQC,mBAAmB,IAAIC,IAAI,QAAsB,kBAAkB;AAE3E,OAAM,SAAUC,+BAA+BA,CAC3CC,aAAuC;EACzC,MAAMC,UAAU,GAAGD,aAAa,CAAC,CAAC,CAAC;EACnC,MAAME,UAAU,GAAGF,aAAa,CAAC,CAAC,CAAC;EACnC,MAAMG,SAAS,GAAGF,UAAU,GAAGC,UAAU,GAAGD,UAAU,GAAGC,UAAU;EACnE,OAAO;8CACqCC,SAAS,MAAMF,UAAU;8CACzBC,UAAU,MAAMC,SAAS;;;;;;;;IAQnEL,IAAI,EAAE;;;;;;;;;;+CAUqCK,SAAS;;;;;;;;gCAQxBA,SAAS;gCACTA,SAAS;;;;;;;;;;;;kCAYPA,SAAS;kCACTA,SAAS;;4BAEfA,SAAS;;;;;;;;GAQlC;AACH;AAEA,OAAM,MAAOC,4BAA4B;EAcvCC,YACIC,MAAgC,EAAEC,MAAgC,EAClEC,WAAqC,EAAEC,UAAU,GAAG,KAAK,EACzDC,UAAU,GAAG,KAAK,EAAEC,IAAA,GAAmB,IAAI,EAC3CC,UAAA,GAAsC,IAAI,EAC1CC,sBAAA,GAAqC,IAAI;IAd7C,KAAAC,aAAa,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC;IAC1B,KAAAC,QAAQ,GAAG,mDAAmD;IAC9D,KAAAf,aAAa,GAA6B,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC;IAalD,IAAI,CAACQ,WAAW,GAAGA,WAAW;IAE9B,IAAI,CAACQ,cAAc,GAAG;MAACC,CAAC,EAAE,CAAC,CAAC,CAAC;MAAEC,CAAC,EAAE,CAAC,CAAC,CAAC;MAAEC,CAAC,EAAE,CAAC,CAAC;IAAC,CAAC;IAC9C,IAAI,CAACC,QAAQ,GAAG,CACdC,IAAI,CAACC,IAAI,CAACd,WAAW,CAAC,CAAC,CAAC,GAAG,IAAI,CAACR,aAAa,CAAC,CAAC,CAAC,CAAC,EACjDqB,IAAI,CAACC,IAAI,CAACd,WAAW,CAAC,CAAC,CAAC,GAAG,IAAI,CAACR,aAAa,CAAC,CAAC,CAAC,CAAC,EAAEQ,WAAW,CAAC,CAAC,CAAC,CAClE;IAED,MAAMe,OAAO,GAAGZ,IAAI,IAAI,IAAI;IAC5B,IAAIY,OAAO,EAAE;MACX,IAAI,CAACT,aAAa,CAACU,IAAI,CAAC,MAAM,CAAC;;IAGjC,MAAMC,yBAAyB,GAAGZ,sBAAsB,IAAI,IAAI;IAChE,IAAIY,yBAAyB,EAAE;MAC7B,IAAI,CAACX,aAAa,CAACU,IAAI,CAAC,wBAAwB,CAAC;;IAGnD,IAAI,CAACf,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAACC,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAACa,OAAO,GAAGA,OAAO;IACtB,IAAI,CAACX,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAACa,yBAAyB,GAAGA,yBAAyB;IAC1D,IAAI,CAACC,SAAS,GACV,yBAAyB,IAAI,CAACd,UAAU,IAAIH,UAAU,IAAIC,UAAU,EAAE;EAC5E;EAEAiB,WAAWA,CAAA;IACT,MAAMC,QAAQ,GAAG;QACbjC,mBAAmB,CAAC,IAAI,CAACiB,UAAU,EAAE,IAAI,CAACa,yBAAyB,CAAC;QAEpE7B,uBAAuB,CACnB,IAAI,CAAC2B,OAAO,EAAE,IAAI,CAACX,UAAU,EAAE,IAAI,CAACH,UAAU,EAAE,IAAI,CAACC,UAAU,CAAC;QACpEX,+BAA+B,CAAC,IAAI,CAACC,aAAa,CAAC;KACtD;IACD,OAAO4B,QAAQ;EACjB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}