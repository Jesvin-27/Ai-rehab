{"ast":null,"code":"/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { util } from '@tensorflow/tfjs-core';\nimport { activationFnSnippet, biasActivationSnippet } from './activation_util';\nimport { getMainHeaderString as main, typeSnippet } from './webgpu_program';\nimport { computeDispatch, computeWorkgroupInfoForMatMul } from './webgpu_util';\nexport function matMulReadFnSource(transposeA, transposeB, fitAOuter = false, fitBOuter = false, fitInner = false, component = 1) {\n  util.assert(transposeA && component === 1 || !transposeA, () => `transposeA ${transposeA} is not compatible with component size ${component}`);\n  const sampleA = `\n      ${transposeA ? `value = getA(batch, col, row);` : `value = getA(batch, row, col);`}\n\n    `;\n  const sampleB = transposeB ? `value = getB(batch, col, row);` : `value = getB(batch, row, col);`;\n  return `\n  fn mm_readA(batch: i32, row: i32, col: i32) -> ${typeSnippet(component)} {\n    var value = ${typeSnippet(component)}(0.0);\n    ${fitAOuter && fitInner ? sampleA : `\n    ${transposeA ? `if(row < uniforms.dimAOuter && col < uniforms.dimInner)` : `if(row < uniforms.aShape[1] && col < uniforms.aShape[2])`}\n    {\n      ${sampleA}\n    }\n    `}\n    return value;\n  }\n\n  fn mm_readB(batch: i32, row: i32, col: i32) -> ${typeSnippet(component)} {\n    var value = ${typeSnippet(component)}(0.0);\n    ${sampleB}\n    return value;\n  }\n  `;\n}\nexport function matMulReadWriteFnSource(hasBias, activation, transposeA, transposeB, fitAOuter = false, fitBOuter = false, fitInner = false, component = 1) {\n  return `\n  ${matMulReadFnSource(transposeA, transposeB, fitAOuter, fitBOuter, fitInner, component)}\n  fn mm_write(batch: i32, row: i32, col: i32, valueIn: ${typeSnippet(component)}) {\n    ${fitAOuter && fitBOuter ? '' : 'if (row < uniforms.dimAOuter && col < uniforms.dimBOuter)'}\n    {\n      var value = valueIn;\n      let coords = vec3<i32>(batch, row, col);\n      ${biasActivationSnippet(hasBias, activation)}\n      setOutputAtCoords(coords[0], coords[1], coords[2], value);\n    }\n  }\n  `;\n}\nconst writeDataToSubAVec4Snippet = (transpose, innerElementSize) => {\n  if (transpose) {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          kStart + inputRow,\n          globalRowStart + inputCol * ${innerElementSize});\n        `;\n  } else {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          globalRow + innerRow,\n          kStart + inputCol * ${innerElementSize});\n        `;\n  }\n};\nconst calculateResultSnippet = (transposeA, innerElementSize, rowPerThread, tileInner) => {\n  if (transposeA) {\n    return `\n      for (var k = 0; k < ${tileInner}; k++) {\n        let BCached0 = mm_Bsub[k][tileCol];\n        let ACached0 = mm_Asub[k][localRow];\n        for (var i = 0; i < ${rowPerThread}; i++) {\n          acc[i] = fma(BCached0, vec4<f32>(ACached0[i]), acc[i]);\n        }\n      }`;\n  } else {\n    let bCachedStr = '';\n    let accStr = '';\n    for (let i = 0; i < innerElementSize; i++) {\n      bCachedStr += `let BCached${i} = mm_Bsub[k * ${innerElementSize} + ${i}][tileCol];`;\n      accStr += `acc[i] = fma(BCached${i}, vec4<f32>(ACached[${i}]), acc[i]);`;\n    }\n    return `\n      for (var k = 0; k < ${tileInner / innerElementSize}; k++) {\n        ${bCachedStr}\n        for (var i = 0; i < ${rowPerThread}; i++) {\n          let ACached = mm_Asub[tileRow + i][k];\n          ${accStr}\n        }\n      }`;\n  }\n};\nexport function makeMatMulPackedVec4Source(workPerThread, workgroupSize, transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32, broadcastBatch = false) {\n  const tileAOuter = workgroupSize[1] * workPerThread[1];\n  const tileBOuter = workgroupSize[0] * workPerThread[0];\n  const tileAWidth = transposeA ? tileAOuter : tileInner;\n  const tileAHight = transposeA ? tileInner : tileAOuter;\n  const innerElementSize = tileAWidth / workgroupSize[0];\n  const rowPerThreadB = tileInner / workgroupSize[1];\n  const rowPerThread = workPerThread[1];\n  const colPerThread = workPerThread[0];\n  util.assert((transposeA && innerElementSize === 4 && workPerThread[1] === 4 || !transposeA && (innerElementSize === 3 || innerElementSize === 4)) && tileAWidth % workgroupSize[0] === 0 && tileInner % workgroupSize[1] === 0 && workPerThread[0] === 4, () => `If transposeA ${transposeA} is true, innerElementSize ${innerElementSize} and workPerThread[1] ${workPerThread[1]} must be 4.\n          Otherwise, innerElementSize ${innerElementSize} must be 3 or 4.\n      tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${workgroupSize[0]}. tileInner ${tileInner} must be divisible by workgroupSize[1] ${workgroupSize[1]}. colPerThread ${workPerThread[0]} must be 4.`);\n  return `\n  var<workgroup> mm_Asub : array<array<vec${innerElementSize}<f32>, ${tileAWidth / innerElementSize}>, ${tileAHight}>;\n  var<workgroup> mm_Bsub : array<array<vec4<f32>, ${tileBOuter / workPerThread[0]}>, ${tileInner}>;\n\n  ${main()} {\n    let localRow = i32(localId.y);\n    let tileRow = localRow * ${rowPerThread};\n    let tileCol = i32(localId.x);\n\n    let globalRow = i32(globalId.y) * ${rowPerThread};\n    let globalCol = i32(globalId.x) * ${colPerThread};\n    let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n    let batchA = ${splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.aShape[0]'};\n    let batchB = ${splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.bShape[0]'};\n    let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n    let numTiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` : `(uniforms.dimInner - 1) / ${tileInner} + 1`};\n    var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n    var acc: array<vec4<f32>, ${rowPerThread}>;\n\n    // Loop over shared dimension.\n    let tileRowB = localRow * ${rowPerThreadB};\n    for (var t = 0; t < numTiles; t++) {\n        // Load one tile of A into local memory.\n        for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n            let inputRow = tileRow + innerRow;\n            let inputCol = tileCol;\n            ${writeDataToSubAVec4Snippet(transposeA, innerElementSize)}\n        }\n\n        // Load one tile of B into local memory.\n        for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow++) {\n            let inputRow = tileRowB + innerRow;\n            let inputCol = tileCol;\n            mm_Bsub[inputRow][inputCol] = mm_readB(batchB, kStart + inputRow, globalCol);\n        }\n        kStart = kStart + ${tileInner};\n        workgroupBarrier();\n\n        // Compute acc values for a single thread.\n        ${calculateResultSnippet(transposeA, innerElementSize, rowPerThread, tileInner)}\n        workgroupBarrier();\n    }\n\n    for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n    }\n  }`;\n}\nconst writeDataToSubASnippet = transpose => {\n  if (transpose) {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          kStart + inputRow,\n          globalRowStart + inputCol);\n        `;\n  } else {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          globalRowStart + inputRow,\n          kStart + inputCol);\n        `;\n  }\n};\nconst readDataFromSubASnippet = transposeA => {\n  return transposeA ? 'let ACached = mm_Asub[k][tileRow + innerRow];' : 'let ACached = mm_Asub[tileRow + innerRow][k];';\n};\n// sequentialAccessByThreads means sequential data in memory is accessed by\n// threads, instead of a single thread (default behavior).\nexport function makeMatMulPackedSource(workPerThread, workgroupSize, transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32, sequentialAccessByThreads = false, broadcastBatch = false) {\n  const tileAOuter = workPerThread[1] * workgroupSize[1];\n  const tileBOuter = workPerThread[0] * workgroupSize[0];\n  const tileAWidth = transposeA ? tileAOuter : tileInner;\n  const tileAHight = transposeA ? tileInner : tileAOuter;\n  util.assert(tileAHight % workgroupSize[1] === 0 && tileAWidth % workgroupSize[0] === 0 && tileInner % workgroupSize[1] === 0, () => `tileAHight ${tileAHight} must be divisible by workgroupSize[1]${workgroupSize[1]}, tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${workgroupSize[0]}, tileInner ${tileInner} must be divisible by workgroupSize[1]${workgroupSize[1]}`);\n  const rowPerThreadA = tileAHight / workgroupSize[1];\n  const colPerThreadA = tileAWidth / workgroupSize[0];\n  const rowPerThreadB = tileInner / workgroupSize[1];\n  const rowPerThread = workPerThread[1];\n  const colPerThread = workPerThread[0];\n  const matmulSnippet = sequentialAccessByThreads ? `\n      let localRow = i32(localId.y);\n      let localCol = i32(localId.x);\n      let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n      let globalColStart = i32(workgroupId.x) * ${tileBOuter};\n\n      // Loop over shared dimension.\n      for (var t = 0; t < numTiles; t++) {\n        // Load one tile of A into local memory.\n        for (var inputRow = localRow; inputRow < ${tileAHight}; inputRow = inputRow + ${workgroupSize[1]}) {\n          for (var inputCol = localCol; inputCol < ${tileAWidth}; inputCol = inputCol + ${workgroupSize[0]}) {\n            ${writeDataToSubASnippet(transposeA)}\n          }\n        }\n        // Load one tile of B into local memory.\n        for (var inputRow = localRow; inputRow < ${tileInner}; inputRow = inputRow + ${workgroupSize[1]}) {\n              for (var inputCol = localCol; inputCol < ${tileBOuter}; inputCol = inputCol + ${workgroupSize[0]}) {\n            mm_Bsub[inputRow][inputCol] = mm_readB(batchB,\n              kStart + inputRow,\n              globalColStart + inputCol);\n          }\n        }\n        kStart = kStart + ${tileInner};\n        workgroupBarrier();\n\n        // Compute acc values for a single thread.\n        var BCached : array<f32, ${colPerThread}>;\n        for (var k = 0; k < ${tileInner}; k++) {\n          for (var inner = 0; inner < ${colPerThread}; inner++) {\n            BCached[inner] = mm_Bsub[k][localCol + inner * ${workgroupSize[0]}];\n          }\n          for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n            let ACached = ${transposeA ? `mm_Asub[k][localRow + innerRow * ${workgroupSize[1]}];` : `mm_Asub[localRow + innerRow * ${workgroupSize[1]}][k];`}\n            for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n              acc[innerRow][innerCol] =\n                  fma(ACached, BCached[innerCol], acc[innerRow][innerCol]);\n            }\n          }\n        }\n        workgroupBarrier();\n      }\n      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        let gRow = globalRowStart + localRow + innerRow * ${workgroupSize[1]};\n        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n          let gCol = globalColStart + localCol + innerCol * ${workgroupSize[0]};\n          mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n        }\n      }\n      ` : `\n  let tileRow = i32(localId.y) * ${rowPerThread};\n  let tileCol = i32(localId.x) * ${colPerThread};\n\n  let globalRow = i32(globalId.y) * ${rowPerThread};\n  let globalCol = i32(globalId.x) * ${colPerThread};\n  let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n  let tileRowA = i32(localId.y) * ${rowPerThreadA};\n  let tileColA = i32(localId.x) * ${colPerThreadA};\n  let tileRowB = i32(localId.y) * ${rowPerThreadB};\n  // Loop over shared dimension.\n  for (var t = 0; t < numTiles; t++) {\n    // Load one tile of A into local memory.\n    for (var innerRow = 0; innerRow < ${rowPerThreadA}; innerRow++) {\n      for (var innerCol = 0; innerCol < ${colPerThreadA}; innerCol++) {\n        let inputRow = tileRowA + innerRow;\n        let inputCol = tileColA + innerCol;\n        ${writeDataToSubASnippet(transposeA)}\n      }\n    }\n\n    // Load one tile of B into local memory.\n    for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow++) {\n      for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n        let inputRow = tileRowB + innerRow;\n        let inputCol = tileCol + innerCol;\n        mm_Bsub[inputRow][inputCol] = mm_readB(batchB,\n          kStart + inputRow,\n          globalCol + innerCol);\n      }\n    }\n    kStart = kStart + ${tileInner};\n    workgroupBarrier();\n\n    // Compute acc values for a single thread.\n    var BCached : array<f32, ${colPerThread}>;\n    for (var k = 0; k < ${tileInner}; k++) {\n      for (var inner = 0; inner < ${colPerThread}; inner++) {\n        BCached[inner] = mm_Bsub[k][tileCol + inner];\n      }\n\n      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        ${readDataFromSubASnippet(transposeA)}\n        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n          acc[innerRow][innerCol] =\n              fma(ACached, BCached[innerCol], acc[innerRow][innerCol]);\n        }\n      }\n    }\n\n    workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n    for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n      mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n          acc[innerRow][innerCol]);\n    }\n  }\n  `;\n  return `\n    var<workgroup> mm_Asub : array<array<f32, ${tileAWidth}>, ${tileAHight}>;\n    var<workgroup> mm_Bsub : array<array<f32, ${tileBOuter}>, ${tileInner}>;\n\n    ${main()} {\n      let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n      let batchA = ${splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.aShape[0]'};\n      let batchB = ${splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.bShape[0]'};\n      let numTiles = ${splitK ? `${Math.ceil(splitedDimInner / tileInner)}` : `(uniforms.dimInner - 1) / ${tileInner} + 1`};\n      var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n      var acc : array<array<f32, ${colPerThread}>, ${rowPerThread}>;\n\n      // Without this initialization strange values show up in acc.\n      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n          acc[innerRow][innerCol] = 0.0;\n        }\n      }\n      ${matmulSnippet}\n    }\n  `;\n}\nconst readVectorASnippet = transpose => {\n  return transpose ? `\n      mm_readA(batchA, colA, globalRow),\n      mm_readA(batchA, colA + 1, globalRow),\n      mm_readA(batchA, colA + 2, globalRow),\n      mm_readA(batchA, colA + 3, globalRow)\n  ` : `\n      mm_readA(batchA, globalRow, colA),\n      mm_readA(batchA, globalRow, colA + 1),\n      mm_readA(batchA, globalRow, colA + 2),\n      mm_readA(batchA, globalRow, colA + 3)\n  `;\n};\nexport function makeVectorMatrixProductSource(workgroupSize, transposeA = false) {\n  util.assert(workgroupSize[1] === 1 && workgroupSize[2] === 1, () => `A linear work group size is required. But got ${workgroupSize}.`);\n  const tileSize = workgroupSize[0] * 4;\n  return `\n    var<workgroup> mm_Asub : array<vec4<f32>, ${workgroupSize[0]}>;\n\n    ${main()} {\n      let tileCol = i32(localId.x);\n      let globalCol = i32(globalId.x);\n      let globalRow = i32(globalId.y);\n\n      let numTiles = (uniforms.dimInner - 1) / ${tileSize} + 1;\n      let batch = i32(globalId.z);\n      let batchA = batch % uniforms.aShape[0];\n      let batchB = batch % uniforms.bShape[0];\n      // Without this initialization strange values show up in acc.\n      var acc = 0.0;\n\n      // Loop over shared dimension.\n      for (var t = 0; t < numTiles; t++) {\n        // Load one tile of A into local memory.\n        let colA = t * ${tileSize} + tileCol * 4;\n        mm_Asub[tileCol] = vec4<f32>(${readVectorASnippet(transposeA)});\n        workgroupBarrier();\n\n        // Compute acc values for a single thread.\n        for (var k = 0; k < ${tileSize / 4}; k++) {\n          let rowB = t * ${tileSize} + k * 4;\n          let BCached = vec4<f32>(mm_readB(batchB, rowB, globalCol),\n                              mm_readB(batchB, rowB + 1, globalCol),\n                              mm_readB(batchB, rowB + 2, globalCol),\n                              mm_readB(batchB, rowB + 3, globalCol));\n\n          let ACached = mm_Asub[k];\n          acc = acc + dot(ACached, BCached);\n        }\n\n        workgroupBarrier();\n      }\n\n      mm_write(batch, globalRow, globalCol, acc);\n    }\n  `;\n}\nexport class MatMulPackedProgram {\n  constructor(aShape, outputShape, transposeA = false, transposeB = false, bias = null, activation = null, preluActivationWeights = null, sequentialAccessByThreads = false) {\n    this.variableNames = ['A', 'B'];\n    this.uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n    this.outputShape = outputShape;\n    this.dispatchLayout = {\n      x: [2],\n      y: [1],\n      z: [0]\n    };\n    const dimInner = transposeA ? aShape[1] : aShape[2];\n    this.isVec4 = (dimInner % 4 === 0 && !transposeA || outputShape[1] % 4 === 0 && transposeA) && outputShape[2] % 4 === 0 && !transposeB;\n    this.outputComponent = this.isVec4 ? 4 : 1;\n    this.isVectorA = outputShape[1] === 1 && !transposeA;\n    if (!this.isVec4 && this.isVectorA) {\n      // For makeVectorMatrixProductSource\n      this.elementsPerThread = [1, 1, 1];\n      this.workgroupSize = [32, 1, 1];\n    } else {\n      const workgroupInfo = computeWorkgroupInfoForMatMul(outputShape[1], dimInner, outputShape[2], transposeA);\n      this.workgroupSize = workgroupInfo.workgroupSize;\n      this.elementsPerThread = workgroupInfo.elementsPerThread;\n    }\n    this.dispatch = computeDispatch(this.dispatchLayout, this.outputShape, this.workgroupSize, this.elementsPerThread);\n    const addBias = bias != null;\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n    if (hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n    this.sequentialAccessByThreads = sequentialAccessByThreads;\n    this.transposeA = transposeA;\n    this.transposeB = transposeB;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n    [this.fitAOuter, this.fitBOuter, this.fitInner] = this.getShapeFit(outputShape[1], outputShape[2], dimInner);\n    this.shaderKey = `matMulPacked_${this.elementsPerThread}_${transposeA}_${transposeB}_${this.activation}_${this.fitAOuter}_${this.fitBOuter}_${this.fitInner}_${this.isVec4}_${this.isVectorA}_${this.sequentialAccessByThreads}`;\n  }\n  getShapeFit(dimAOuter, dimBOuter, dimInner) {\n    const tileAOuter = this.workgroupSize[1] * this.elementsPerThread[1];\n    const tileBOuter = this.workgroupSize[0] * this.elementsPerThread[0];\n    if (!this.isVec4 && this.isVectorA) {\n      // For makeVectorMatrixProductSource\n      this.tileInner = this.workgroupSize[0] * 4;\n    } else {\n      this.tileInner = tileBOuter;\n    }\n    const fitAOuter = dimAOuter % tileAOuter === 0;\n    const fitBOuter = dimBOuter % tileBOuter === 0;\n    const fitInner = dimInner % this.tileInner === 0;\n    return [fitAOuter, fitBOuter, fitInner];\n  }\n  getUserCode() {\n    const userCode = `\n      ${activationFnSnippet(this.activation, this.hasPreluActivationWeights, this.isVec4)}\n      ${matMulReadWriteFnSource(this.addBias, this.activation, false /* transposeA is implemented in makeMatMulPackedSource */, this.transposeB, this.fitAOuter, this.fitBOuter, this.fitInner, this.isVec4 ? 4 : 1)}\n      ${this.isVec4 ? makeMatMulPackedVec4Source(this.elementsPerThread, this.workgroupSize, this.transposeA, this.tileInner, false, null, true) : this.isVectorA ? makeVectorMatrixProductSource(this.workgroupSize, this.transposeA) : makeMatMulPackedSource(this.elementsPerThread, this.workgroupSize, this.transposeA, this.tileInner, false, null, this.sequentialAccessByThreads, true)}\n    `;\n    return userCode;\n  }\n}","map":{"version":3,"names":["util","activationFnSnippet","biasActivationSnippet","getMainHeaderString","main","typeSnippet","computeDispatch","computeWorkgroupInfoForMatMul","matMulReadFnSource","transposeA","transposeB","fitAOuter","fitBOuter","fitInner","component","assert","sampleA","sampleB","matMulReadWriteFnSource","hasBias","activation","writeDataToSubAVec4Snippet","transpose","innerElementSize","calculateResultSnippet","rowPerThread","tileInner","bCachedStr","accStr","i","makeMatMulPackedVec4Source","workPerThread","workgroupSize","splitK","splitedDimInner","broadcastBatch","tileAOuter","tileBOuter","tileAWidth","tileAHight","rowPerThreadB","colPerThread","Math","ceil","writeDataToSubASnippet","readDataFromSubASnippet","makeMatMulPackedSource","sequentialAccessByThreads","rowPerThreadA","colPerThreadA","matmulSnippet","readVectorASnippet","makeVectorMatrixProductSource","tileSize","MatMulPackedProgram","constructor","aShape","outputShape","bias","preluActivationWeights","variableNames","uniforms","dispatchLayout","x","y","z","dimInner","isVec4","outputComponent","isVectorA","elementsPerThread","workgroupInfo","dispatch","addBias","hasPreluActivationWeights","push","getShapeFit","shaderKey","dimAOuter","dimBOuter","getUserCode","userCode"],"sources":["/Users/jesvinblazegmail.com/PycharmProjects/tfjs-backend-webgpu/src/matmul_packed_webgpu.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {activationFnSnippet, biasActivationSnippet} from './activation_util';\nimport {getMainHeaderString as main, typeSnippet, WebGPUProgram} from './webgpu_program';\nimport {computeDispatch, computeWorkgroupInfoForMatMul} from './webgpu_util';\n\nexport function matMulReadFnSource(\n    transposeA: boolean, transposeB: boolean, fitAOuter = false,\n    fitBOuter = false, fitInner = false, component = 1) {\n  util.assert(\n      transposeA && component === 1 || !transposeA,\n      () => `transposeA ${transposeA} is not compatible with component size ${\n          component}`);\n  const sampleA = `\n      ${\n      transposeA ? `value = getA(batch, col, row);` :\n                   `value = getA(batch, row, col);`}\n\n    `;\n  const sampleB = transposeB ? `value = getB(batch, col, row);` :\n                               `value = getB(batch, row, col);`;\n\n  return `\n  fn mm_readA(batch: i32, row: i32, col: i32) -> ${typeSnippet(component)} {\n    var value = ${typeSnippet(component)}(0.0);\n    ${\n      fitAOuter && fitInner ?\n          sampleA :\n          `\n    ${\n              transposeA ?\n                  `if(row < uniforms.dimAOuter && col < uniforms.dimInner)` :\n                  `if(row < uniforms.aShape[1] && col < uniforms.aShape[2])`}\n    {\n      ${sampleA}\n    }\n    `}\n    return value;\n  }\n\n  fn mm_readB(batch: i32, row: i32, col: i32) -> ${typeSnippet(component)} {\n    var value = ${typeSnippet(component)}(0.0);\n    ${sampleB}\n    return value;\n  }\n  `;\n}\n\nexport function matMulReadWriteFnSource(\n    hasBias: boolean, activation: backend_util.Activation, transposeA: boolean,\n    transposeB: boolean, fitAOuter = false, fitBOuter = false, fitInner = false,\n    component = 1) {\n  return `\n  ${\n      matMulReadFnSource(\n          transposeA, transposeB, fitAOuter, fitBOuter, fitInner, component)}\n  fn mm_write(batch: i32, row: i32, col: i32, valueIn: ${\n      typeSnippet(component)}) {\n    ${\n      fitAOuter && fitBOuter ?\n          '' :\n          'if (row < uniforms.dimAOuter && col < uniforms.dimBOuter)'}\n    {\n      var value = valueIn;\n      let coords = vec3<i32>(batch, row, col);\n      ${biasActivationSnippet(hasBias, activation)}\n      setOutputAtCoords(coords[0], coords[1], coords[2], value);\n    }\n  }\n  `;\n}\n\nconst writeDataToSubAVec4Snippet =\n    (transpose: boolean, innerElementSize: number) => {\n      if (transpose) {\n        return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          kStart + inputRow,\n          globalRowStart + inputCol * ${innerElementSize});\n        `;\n\n      } else {\n        return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          globalRow + innerRow,\n          kStart + inputCol * ${innerElementSize});\n        `;\n      }\n    };\n\nconst calculateResultSnippet =\n    (transposeA: boolean, innerElementSize: number, rowPerThread: number,\n     tileInner: number) => {\n      if (transposeA) {\n        return `\n      for (var k = 0; k < ${tileInner}; k++) {\n        let BCached0 = mm_Bsub[k][tileCol];\n        let ACached0 = mm_Asub[k][localRow];\n        for (var i = 0; i < ${rowPerThread}; i++) {\n          acc[i] = fma(BCached0, vec4<f32>(ACached0[i]), acc[i]);\n        }\n      }`;\n      } else {\n        let bCachedStr = '';\n        let accStr = '';\n        for (let i = 0; i < innerElementSize; i++) {\n          bCachedStr += `let BCached${i} = mm_Bsub[k * ${innerElementSize} + ${\n              i}][tileCol];`;\n          accStr +=\n              `acc[i] = fma(BCached${i}, vec4<f32>(ACached[${i}]), acc[i]);`;\n        }\n        return `\n      for (var k = 0; k < ${tileInner / innerElementSize}; k++) {\n        ${bCachedStr}\n        for (var i = 0; i < ${rowPerThread}; i++) {\n          let ACached = mm_Asub[tileRow + i][k];\n          ${accStr}\n        }\n      }`;\n      }\n    };\n\nexport function makeMatMulPackedVec4Source(\n    workPerThread: number[], workgroupSize: [number, number, number],\n    transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32,\n    broadcastBatch = false): string {\n  const tileAOuter = workgroupSize[1] * workPerThread[1];\n  const tileBOuter = workgroupSize[0] * workPerThread[0];\n  const tileAWidth = transposeA ? tileAOuter : tileInner;\n  const tileAHight = transposeA ? tileInner : tileAOuter;\n  const innerElementSize = tileAWidth / workgroupSize[0];\n  const rowPerThreadB = tileInner / workgroupSize[1];\n  const rowPerThread = workPerThread[1];\n  const colPerThread = workPerThread[0];\n  util.assert(\n      ((transposeA && innerElementSize === 4 && workPerThread[1] === 4) ||\n       (!transposeA && (innerElementSize === 3 || innerElementSize === 4))) &&\n          tileAWidth % workgroupSize[0] === 0 &&\n          tileInner % workgroupSize[1] === 0 && workPerThread[0] === 4,\n      () => `If transposeA ${transposeA} is true, innerElementSize ${\n          innerElementSize} and workPerThread[1] ${workPerThread[1]} must be 4.\n          Otherwise, innerElementSize ${innerElementSize} must be 3 or 4.\n      tileAWidth ${tileAWidth} must be divisible by workgroupSize[0]${\n          workgroupSize[0]}. tileInner ${\n          tileInner} must be divisible by workgroupSize[1] ${\n          workgroupSize[1]}. colPerThread ${workPerThread[0]} must be 4.`);\n  return `\n  var<workgroup> mm_Asub : array<array<vec${innerElementSize}<f32>, ${\n      tileAWidth / innerElementSize}>, ${tileAHight}>;\n  var<workgroup> mm_Bsub : array<array<vec4<f32>, ${\n      tileBOuter / workPerThread[0]}>, ${tileInner}>;\n\n  ${main()} {\n    let localRow = i32(localId.y);\n    let tileRow = localRow * ${rowPerThread};\n    let tileCol = i32(localId.x);\n\n    let globalRow = i32(globalId.y) * ${rowPerThread};\n    let globalCol = i32(globalId.x) * ${colPerThread};\n    let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n    let batchA = ${\n      splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.aShape[0]'};\n    let batchB = ${\n      splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.bShape[0]'};\n    let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n    let numTiles = ${\n      splitK ? `${Math.ceil(splitedDimInner / tileInner)}` :\n               `(uniforms.dimInner - 1) / ${tileInner} + 1`};\n    var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n    var acc: array<vec4<f32>, ${rowPerThread}>;\n\n    // Loop over shared dimension.\n    let tileRowB = localRow * ${rowPerThreadB};\n    for (var t = 0; t < numTiles; t++) {\n        // Load one tile of A into local memory.\n        for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n            let inputRow = tileRow + innerRow;\n            let inputCol = tileCol;\n            ${writeDataToSubAVec4Snippet(transposeA, innerElementSize)}\n        }\n\n        // Load one tile of B into local memory.\n        for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow++) {\n            let inputRow = tileRowB + innerRow;\n            let inputCol = tileCol;\n            mm_Bsub[inputRow][inputCol] = mm_readB(batchB, kStart + inputRow, globalCol);\n        }\n        kStart = kStart + ${tileInner};\n        workgroupBarrier();\n\n        // Compute acc values for a single thread.\n        ${\n      calculateResultSnippet(\n          transposeA, innerElementSize, rowPerThread, tileInner)}\n        workgroupBarrier();\n    }\n\n    for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n    }\n  }`;\n}\n\nconst writeDataToSubASnippet = (transpose: boolean) => {\n  if (transpose) {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          kStart + inputRow,\n          globalRowStart + inputCol);\n        `;\n\n  } else {\n    return `\n        mm_Asub[inputRow][inputCol] = mm_readA(batchA,\n          globalRowStart + inputRow,\n          kStart + inputCol);\n        `;\n  }\n};\n\nconst readDataFromSubASnippet = (transposeA: boolean) => {\n  return transposeA ? 'let ACached = mm_Asub[k][tileRow + innerRow];' :\n\n                      'let ACached = mm_Asub[tileRow + innerRow][k];';\n};\n\n// sequentialAccessByThreads means sequential data in memory is accessed by\n// threads, instead of a single thread (default behavior).\nexport function makeMatMulPackedSource(\n    workPerThread: number[], workgroupSize: [number, number, number],\n    transposeA = false, tileInner = 32, splitK = false, splitedDimInner = 32,\n    sequentialAccessByThreads = false, broadcastBatch = false): string {\n  const tileAOuter = workPerThread[1] * workgroupSize[1];\n  const tileBOuter = workPerThread[0] * workgroupSize[0];\n  const tileAWidth = transposeA ? tileAOuter : tileInner;\n  const tileAHight = transposeA ? tileInner : tileAOuter;\n  util.assert(\n      tileAHight % workgroupSize[1] === 0 &&\n          tileAWidth % workgroupSize[0] === 0 &&\n          tileInner % workgroupSize[1] === 0,\n      () => `tileAHight ${tileAHight} must be divisible by workgroupSize[1]${\n          workgroupSize[1]}, tileAWidth ${\n          tileAWidth} must be divisible by workgroupSize[0]${\n          workgroupSize[0]}, tileInner ${\n          tileInner} must be divisible by workgroupSize[1]${workgroupSize[1]}`);\n  const rowPerThreadA = tileAHight / workgroupSize[1];\n  const colPerThreadA = tileAWidth / workgroupSize[0];\n  const rowPerThreadB = tileInner / workgroupSize[1];\n  const rowPerThread = workPerThread[1];\n  const colPerThread = workPerThread[0];\n  const matmulSnippet = sequentialAccessByThreads ?\n      `\n      let localRow = i32(localId.y);\n      let localCol = i32(localId.x);\n      let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n      let globalColStart = i32(workgroupId.x) * ${tileBOuter};\n\n      // Loop over shared dimension.\n      for (var t = 0; t < numTiles; t++) {\n        // Load one tile of A into local memory.\n        for (var inputRow = localRow; inputRow < ${\n          tileAHight}; inputRow = inputRow + ${workgroupSize[1]}) {\n          for (var inputCol = localCol; inputCol < ${\n          tileAWidth}; inputCol = inputCol + ${workgroupSize[0]}) {\n            ${writeDataToSubASnippet(transposeA)}\n          }\n        }\n        // Load one tile of B into local memory.\n        for (var inputRow = localRow; inputRow < ${\n          tileInner}; inputRow = inputRow + ${workgroupSize[1]}) {\n              for (var inputCol = localCol; inputCol < ${\n          tileBOuter}; inputCol = inputCol + ${workgroupSize[0]}) {\n            mm_Bsub[inputRow][inputCol] = mm_readB(batchB,\n              kStart + inputRow,\n              globalColStart + inputCol);\n          }\n        }\n        kStart = kStart + ${tileInner};\n        workgroupBarrier();\n\n        // Compute acc values for a single thread.\n        var BCached : array<f32, ${colPerThread}>;\n        for (var k = 0; k < ${tileInner}; k++) {\n          for (var inner = 0; inner < ${colPerThread}; inner++) {\n            BCached[inner] = mm_Bsub[k][localCol + inner * ${workgroupSize[0]}];\n          }\n          for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n            let ACached = ${\n          transposeA ?\n              `mm_Asub[k][localRow + innerRow * ${workgroupSize[1]}];` :\n              `mm_Asub[localRow + innerRow * ${workgroupSize[1]}][k];`}\n            for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n              acc[innerRow][innerCol] =\n                  fma(ACached, BCached[innerCol], acc[innerRow][innerCol]);\n            }\n          }\n        }\n        workgroupBarrier();\n      }\n      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        let gRow = globalRowStart + localRow + innerRow * ${workgroupSize[1]};\n        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n          let gCol = globalColStart + localCol + innerCol * ${workgroupSize[0]};\n          mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n        }\n      }\n      ` :\n      `\n  let tileRow = i32(localId.y) * ${rowPerThread};\n  let tileCol = i32(localId.x) * ${colPerThread};\n\n  let globalRow = i32(globalId.y) * ${rowPerThread};\n  let globalCol = i32(globalId.x) * ${colPerThread};\n  let globalRowStart = i32(workgroupId.y) * ${tileAOuter};\n\n  let tileRowA = i32(localId.y) * ${rowPerThreadA};\n  let tileColA = i32(localId.x) * ${colPerThreadA};\n  let tileRowB = i32(localId.y) * ${rowPerThreadB};\n  // Loop over shared dimension.\n  for (var t = 0; t < numTiles; t++) {\n    // Load one tile of A into local memory.\n    for (var innerRow = 0; innerRow < ${rowPerThreadA}; innerRow++) {\n      for (var innerCol = 0; innerCol < ${colPerThreadA}; innerCol++) {\n        let inputRow = tileRowA + innerRow;\n        let inputCol = tileColA + innerCol;\n        ${writeDataToSubASnippet(transposeA)}\n      }\n    }\n\n    // Load one tile of B into local memory.\n    for (var innerRow = 0; innerRow < ${rowPerThreadB}; innerRow++) {\n      for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n        let inputRow = tileRowB + innerRow;\n        let inputCol = tileCol + innerCol;\n        mm_Bsub[inputRow][inputCol] = mm_readB(batchB,\n          kStart + inputRow,\n          globalCol + innerCol);\n      }\n    }\n    kStart = kStart + ${tileInner};\n    workgroupBarrier();\n\n    // Compute acc values for a single thread.\n    var BCached : array<f32, ${colPerThread}>;\n    for (var k = 0; k < ${tileInner}; k++) {\n      for (var inner = 0; inner < ${colPerThread}; inner++) {\n        BCached[inner] = mm_Bsub[k][tileCol + inner];\n      }\n\n      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        ${readDataFromSubASnippet(transposeA)}\n        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n          acc[innerRow][innerCol] =\n              fma(ACached, BCached[innerCol], acc[innerRow][innerCol]);\n        }\n      }\n    }\n\n    workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n    for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n      mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n          acc[innerRow][innerCol]);\n    }\n  }\n  `;\n\n  return `\n    var<workgroup> mm_Asub : array<array<f32, ${tileAWidth}>, ${tileAHight}>;\n    var<workgroup> mm_Bsub : array<array<f32, ${tileBOuter}>, ${tileInner}>;\n\n    ${main()} {\n      let batch = ${splitK ? '0' : 'i32(globalId.z)'};\n      let batchA = ${\n      splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.aShape[0]'};\n      let batchB = ${\n      splitK || !broadcastBatch ? 'batch' : 'batch % uniforms.bShape[0]'};\n      let numTiles = ${\n      splitK ? `${Math.ceil(splitedDimInner / tileInner)}` :\n               `(uniforms.dimInner - 1) / ${tileInner} + 1`};\n      var kStart = ${splitK ? `i32(globalId.z) * ${splitedDimInner}` : '0'};\n\n      var acc : array<array<f32, ${colPerThread}>, ${rowPerThread}>;\n\n      // Without this initialization strange values show up in acc.\n      for (var innerRow = 0; innerRow < ${rowPerThread}; innerRow++) {\n        for (var innerCol = 0; innerCol < ${colPerThread}; innerCol++) {\n          acc[innerRow][innerCol] = 0.0;\n        }\n      }\n      ${matmulSnippet}\n    }\n  `;\n}\n\nconst readVectorASnippet = (transpose: boolean) => {\n  return transpose ? `\n      mm_readA(batchA, colA, globalRow),\n      mm_readA(batchA, colA + 1, globalRow),\n      mm_readA(batchA, colA + 2, globalRow),\n      mm_readA(batchA, colA + 3, globalRow)\n  ` :\n                     `\n      mm_readA(batchA, globalRow, colA),\n      mm_readA(batchA, globalRow, colA + 1),\n      mm_readA(batchA, globalRow, colA + 2),\n      mm_readA(batchA, globalRow, colA + 3)\n  `;\n};\n\nexport function makeVectorMatrixProductSource(\n    workgroupSize: [number, number, number], transposeA = false): string {\n  util.assert(\n      workgroupSize[1] === 1 && workgroupSize[2] === 1,\n      () => `A linear work group size is required. But got ${workgroupSize}.`);\n  const tileSize = workgroupSize[0] * 4;\n  return `\n    var<workgroup> mm_Asub : array<vec4<f32>, ${workgroupSize[0]}>;\n\n    ${main()} {\n      let tileCol = i32(localId.x);\n      let globalCol = i32(globalId.x);\n      let globalRow = i32(globalId.y);\n\n      let numTiles = (uniforms.dimInner - 1) / ${tileSize} + 1;\n      let batch = i32(globalId.z);\n      let batchA = batch % uniforms.aShape[0];\n      let batchB = batch % uniforms.bShape[0];\n      // Without this initialization strange values show up in acc.\n      var acc = 0.0;\n\n      // Loop over shared dimension.\n      for (var t = 0; t < numTiles; t++) {\n        // Load one tile of A into local memory.\n        let colA = t * ${tileSize} + tileCol * 4;\n        mm_Asub[tileCol] = vec4<f32>(${readVectorASnippet(transposeA)});\n        workgroupBarrier();\n\n        // Compute acc values for a single thread.\n        for (var k = 0; k < ${tileSize / 4}; k++) {\n          let rowB = t * ${tileSize} + k * 4;\n          let BCached = vec4<f32>(mm_readB(batchB, rowB, globalCol),\n                              mm_readB(batchB, rowB + 1, globalCol),\n                              mm_readB(batchB, rowB + 2, globalCol),\n                              mm_readB(batchB, rowB + 3, globalCol));\n\n          let ACached = mm_Asub[k];\n          acc = acc + dot(ACached, BCached);\n        }\n\n        workgroupBarrier();\n      }\n\n      mm_write(batch, globalRow, globalCol, acc);\n    }\n  `;\n}\n\nexport class MatMulPackedProgram implements WebGPUProgram {\n  outputShape: number[];\n  shaderKey: string;\n  dispatchLayout: {x: number[], y: number[], z: number[]};\n  dispatch: [number, number, number];\n  variableNames = ['A', 'B'];\n  uniforms = `dimAOuter : i32, dimBOuter : i32, dimInner : i32,`;\n  workgroupSize: [number, number, number];\n  elementsPerThread: [number, number, number];\n  transposeA: boolean;\n  transposeB: boolean;\n  addBias: boolean;\n  activation: backend_util.Activation;\n  hasPreluActivationWeights: boolean;\n  fitAOuter: boolean;\n  fitBOuter: boolean;\n  fitInner: boolean;\n  tileInner: number;\n  isVectorA: boolean;\n  isVec4: boolean;\n  outputComponent: number;\n  private sequentialAccessByThreads: boolean;\n\n  constructor(\n      aShape: [number, number, number], outputShape: [number, number, number],\n      transposeA = false, transposeB = false, bias: TensorInfo = null,\n      activation: backend_util.Activation = null,\n      preluActivationWeights: TensorInfo = null,\n      sequentialAccessByThreads = false) {\n    this.outputShape = outputShape;\n    this.dispatchLayout = {x: [2], y: [1], z: [0]};\n    const dimInner = transposeA ? aShape[1] : aShape[2];\n    this.isVec4 = ((dimInner % 4 === 0 && !transposeA) ||\n                   (outputShape[1] % 4 === 0 && transposeA)) &&\n        outputShape[2] % 4 === 0 && !transposeB;\n    this.outputComponent = this.isVec4 ? 4 : 1;\n    this.isVectorA = outputShape[1] === 1 && !transposeA;\n\n    if (!this.isVec4 && this.isVectorA) {\n      // For makeVectorMatrixProductSource\n      this.elementsPerThread = [1, 1, 1];\n      this.workgroupSize = [32, 1, 1];\n    } else {\n      const workgroupInfo = computeWorkgroupInfoForMatMul(\n          outputShape[1], dimInner, outputShape[2], transposeA);\n      this.workgroupSize = workgroupInfo.workgroupSize;\n      this.elementsPerThread = workgroupInfo.elementsPerThread;\n    }\n\n    this.dispatch = computeDispatch(\n        this.dispatchLayout, this.outputShape, this.workgroupSize,\n        this.elementsPerThread);\n\n    const addBias = bias != null;\n    const hasPreluActivationWeights = preluActivationWeights != null;\n    if (addBias) {\n      this.variableNames.push('bias');\n    }\n\n    if (hasPreluActivationWeights) {\n      this.variableNames.push('preluActivationWeights');\n    }\n\n    this.sequentialAccessByThreads = sequentialAccessByThreads;\n    this.transposeA = transposeA;\n    this.transposeB = transposeB;\n    this.addBias = addBias;\n    this.activation = activation;\n    this.hasPreluActivationWeights = hasPreluActivationWeights;\n    [this.fitAOuter, this.fitBOuter, this.fitInner] =\n        this.getShapeFit(outputShape[1], outputShape[2], dimInner);\n    this.shaderKey = `matMulPacked_${this.elementsPerThread}_${transposeA}_${\n        transposeB}_${this.activation}_${this.fitAOuter}_${this.fitBOuter}_${\n        this.fitInner}_${this.isVec4}_${this.isVectorA}_${\n        this.sequentialAccessByThreads}`;\n  }\n\n  getShapeFit(dimAOuter: number, dimBOuter: number, dimInner: number):\n      boolean[] {\n    const tileAOuter = this.workgroupSize[1] * this.elementsPerThread[1];\n    const tileBOuter = this.workgroupSize[0] * this.elementsPerThread[0];\n\n    if (!this.isVec4 && this.isVectorA) {\n      // For makeVectorMatrixProductSource\n      this.tileInner = this.workgroupSize[0] * 4;\n    } else {\n      this.tileInner = tileBOuter;\n    }\n\n    const fitAOuter = dimAOuter % tileAOuter === 0;\n    const fitBOuter = dimBOuter % tileBOuter === 0;\n    const fitInner = dimInner % this.tileInner === 0;\n    return [fitAOuter, fitBOuter, fitInner];\n  }\n\n  getUserCode(): string {\n    const userCode = `\n      ${\n        activationFnSnippet(\n            this.activation, this.hasPreluActivationWeights, this.isVec4)}\n      ${\n        matMulReadWriteFnSource(\n            this.addBias, this.activation,\n            false /* transposeA is implemented in makeMatMulPackedSource */,\n            this.transposeB, this.fitAOuter, this.fitBOuter, this.fitInner,\n            this.isVec4 ? 4 : 1)}\n      ${\n        this.isVec4 ?\n            makeMatMulPackedVec4Source(\n                this.elementsPerThread, this.workgroupSize, this.transposeA,\n                this.tileInner, false, null, true) :\n            (this.isVectorA ? makeVectorMatrixProductSource(\n                                  this.workgroupSize, this.transposeA) :\n                              makeMatMulPackedSource(\n                                  this.elementsPerThread, this.workgroupSize,\n                                  this.transposeA, this.tileInner, false, null,\n                                  this.sequentialAccessByThreads, true))}\n    `;\n    return userCode;\n  }\n}\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAkCA,IAAI,QAAO,uBAAuB;AAEpE,SAAQC,mBAAmB,EAAEC,qBAAqB,QAAO,mBAAmB;AAC5E,SAAQC,mBAAmB,IAAIC,IAAI,EAAEC,WAAW,QAAsB,kBAAkB;AACxF,SAAQC,eAAe,EAAEC,6BAA6B,QAAO,eAAe;AAE5E,OAAM,SAAUC,kBAAkBA,CAC9BC,UAAmB,EAAEC,UAAmB,EAAEC,SAAS,GAAG,KAAK,EAC3DC,SAAS,GAAG,KAAK,EAAEC,QAAQ,GAAG,KAAK,EAAEC,SAAS,GAAG,CAAC;EACpDd,IAAI,CAACe,MAAM,CACPN,UAAU,IAAIK,SAAS,KAAK,CAAC,IAAI,CAACL,UAAU,EAC5C,MAAM,cAAcA,UAAU,0CAC1BK,SAAS,EAAE,CAAC;EACpB,MAAME,OAAO,GAAG;QAEZP,UAAU,GAAG,gCAAgC,GAChC,gCAAgC;;KAE9C;EACH,MAAMQ,OAAO,GAAGP,UAAU,GAAG,gCAAgC,GAChC,gCAAgC;EAE7D,OAAO;mDAC0CL,WAAW,CAACS,SAAS,CAAC;kBACvDT,WAAW,CAACS,SAAS,CAAC;MAElCH,SAAS,IAAIE,QAAQ,GACjBG,OAAO,GACP;MAEIP,UAAU,GACN,yDAAyD,GACzD,0DAA0D;;QAEpEO,OAAO;;KAEV;;;;mDAI8CX,WAAW,CAACS,SAAS,CAAC;kBACvDT,WAAW,CAACS,SAAS,CAAC;MAClCG,OAAO;;;GAGV;AACH;AAEA,OAAM,SAAUC,uBAAuBA,CACnCC,OAAgB,EAAEC,UAAmC,EAAEX,UAAmB,EAC1EC,UAAmB,EAAEC,SAAS,GAAG,KAAK,EAAEC,SAAS,GAAG,KAAK,EAAEC,QAAQ,GAAG,KAAK,EAC3EC,SAAS,GAAG,CAAC;EACf,OAAO;IAEHN,kBAAkB,CACdC,UAAU,EAAEC,UAAU,EAAEC,SAAS,EAAEC,SAAS,EAAEC,QAAQ,EAAEC,SAAS,CAAC;yDAEtET,WAAW,CAACS,SAAS,CAAC;MAEtBH,SAAS,IAAIC,SAAS,GAClB,EAAE,GACF,2DAA2D;;;;QAI7DV,qBAAqB,CAACiB,OAAO,EAAEC,UAAU,CAAC;;;;GAI/C;AACH;AAEA,MAAMC,0BAA0B,GAC5BA,CAACC,SAAkB,EAAEC,gBAAwB,KAAI;EAC/C,IAAID,SAAS,EAAE;IACb,OAAO;;;wCAGyBC,gBAAgB;SAC/C;GAEF,MAAM;IACL,OAAO;;;gCAGiBA,gBAAgB;SACvC;;AAEL,CAAC;AAEL,MAAMC,sBAAsB,GACxBA,CAACf,UAAmB,EAAEc,gBAAwB,EAAEE,YAAoB,EACnEC,SAAiB,KAAI;EACpB,IAAIjB,UAAU,EAAE;IACd,OAAO;4BACaiB,SAAS;;;8BAGPD,YAAY;;;QAGlC;GACD,MAAM;IACL,IAAIE,UAAU,GAAG,EAAE;IACnB,IAAIC,MAAM,GAAG,EAAE;IACf,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGN,gBAAgB,EAAEM,CAAC,EAAE,EAAE;MACzCF,UAAU,IAAI,cAAcE,CAAC,kBAAkBN,gBAAgB,MAC3DM,CAAC,aAAa;MAClBD,MAAM,IACF,uBAAuBC,CAAC,uBAAuBA,CAAC,cAAc;;IAEpE,OAAO;4BACaH,SAAS,GAAGH,gBAAgB;UAC9CI,UAAU;8BACUF,YAAY;;YAE9BG,MAAM;;QAEV;;AAEJ,CAAC;AAEL,OAAM,SAAUE,0BAA0BA,CACtCC,aAAuB,EAAEC,aAAuC,EAChEvB,UAAU,GAAG,KAAK,EAAEiB,SAAS,GAAG,EAAE,EAAEO,MAAM,GAAG,KAAK,EAAEC,eAAe,GAAG,EAAE,EACxEC,cAAc,GAAG,KAAK;EACxB,MAAMC,UAAU,GAAGJ,aAAa,CAAC,CAAC,CAAC,GAAGD,aAAa,CAAC,CAAC,CAAC;EACtD,MAAMM,UAAU,GAAGL,aAAa,CAAC,CAAC,CAAC,GAAGD,aAAa,CAAC,CAAC,CAAC;EACtD,MAAMO,UAAU,GAAG7B,UAAU,GAAG2B,UAAU,GAAGV,SAAS;EACtD,MAAMa,UAAU,GAAG9B,UAAU,GAAGiB,SAAS,GAAGU,UAAU;EACtD,MAAMb,gBAAgB,GAAGe,UAAU,GAAGN,aAAa,CAAC,CAAC,CAAC;EACtD,MAAMQ,aAAa,GAAGd,SAAS,GAAGM,aAAa,CAAC,CAAC,CAAC;EAClD,MAAMP,YAAY,GAAGM,aAAa,CAAC,CAAC,CAAC;EACrC,MAAMU,YAAY,GAAGV,aAAa,CAAC,CAAC,CAAC;EACrC/B,IAAI,CAACe,MAAM,CACP,CAAEN,UAAU,IAAIc,gBAAgB,KAAK,CAAC,IAAIQ,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,IAC9D,CAACtB,UAAU,KAAKc,gBAAgB,KAAK,CAAC,IAAIA,gBAAgB,KAAK,CAAC,CAAE,KAChEe,UAAU,GAAGN,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,IACnCN,SAAS,GAAGM,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,IAAID,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,EAChE,MAAM,iBAAiBtB,UAAU,8BAC7Bc,gBAAgB,yBAAyBQ,aAAa,CAAC,CAAC,CAAC;wCAC3BR,gBAAgB;mBACrCe,UAAU,yCACnBN,aAAa,CAAC,CAAC,CAAC,eAChBN,SAAS,0CACTM,aAAa,CAAC,CAAC,CAAC,kBAAkBD,aAAa,CAAC,CAAC,CAAC,aAAa,CAAC;EACxE,OAAO;4CACmCR,gBAAgB,UACtDe,UAAU,GAAGf,gBAAgB,MAAMgB,UAAU;oDAE7CF,UAAU,GAAGN,aAAa,CAAC,CAAC,CAAC,MAAML,SAAS;;IAE9CtB,IAAI,EAAE;;+BAEqBqB,YAAY;;;wCAGHA,YAAY;wCACZgB,YAAY;kBAClCR,MAAM,GAAG,GAAG,GAAG,iBAAiB;mBAE5CA,MAAM,IAAI,CAACE,cAAc,GAAG,OAAO,GAAG,4BAA4B;mBAElEF,MAAM,IAAI,CAACE,cAAc,GAAG,OAAO,GAAG,4BAA4B;gDACxBC,UAAU;;qBAGpDH,MAAM,GAAG,GAAGS,IAAI,CAACC,IAAI,CAACT,eAAe,GAAGR,SAAS,CAAC,EAAE,GAC3C,6BAA6BA,SAAS,MAAM;mBACxCO,MAAM,GAAG,qBAAqBC,eAAe,EAAE,GAAG,GAAG;;gCAExCT,YAAY;;;gCAGZe,aAAa;;;4CAGDf,YAAY;;;cAG1CJ,0BAA0B,CAACZ,UAAU,EAAEc,gBAAgB,CAAC;;;;4CAI1BiB,aAAa;;;;;4BAK7Bd,SAAS;;;;UAK/BF,sBAAsB,CAClBf,UAAU,EAAEc,gBAAgB,EAAEE,YAAY,EAAEC,SAAS,CAAC;;;;wCAIxBD,YAAY;;;IAGhD;AACJ;AAEA,MAAMmB,sBAAsB,GAAItB,SAAkB,IAAI;EACpD,IAAIA,SAAS,EAAE;IACb,OAAO;;;;SAIF;GAEN,MAAM;IACL,OAAO;;;;SAIF;;AAET,CAAC;AAED,MAAMuB,uBAAuB,GAAIpC,UAAmB,IAAI;EACtD,OAAOA,UAAU,GAAG,+CAA+C,GAE/C,+CAA+C;AACrE,CAAC;AAED;AACA;AACA,OAAM,SAAUqC,sBAAsBA,CAClCf,aAAuB,EAAEC,aAAuC,EAChEvB,UAAU,GAAG,KAAK,EAAEiB,SAAS,GAAG,EAAE,EAAEO,MAAM,GAAG,KAAK,EAAEC,eAAe,GAAG,EAAE,EACxEa,yBAAyB,GAAG,KAAK,EAAEZ,cAAc,GAAG,KAAK;EAC3D,MAAMC,UAAU,GAAGL,aAAa,CAAC,CAAC,CAAC,GAAGC,aAAa,CAAC,CAAC,CAAC;EACtD,MAAMK,UAAU,GAAGN,aAAa,CAAC,CAAC,CAAC,GAAGC,aAAa,CAAC,CAAC,CAAC;EACtD,MAAMM,UAAU,GAAG7B,UAAU,GAAG2B,UAAU,GAAGV,SAAS;EACtD,MAAMa,UAAU,GAAG9B,UAAU,GAAGiB,SAAS,GAAGU,UAAU;EACtDpC,IAAI,CAACe,MAAM,CACPwB,UAAU,GAAGP,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,IAC/BM,UAAU,GAAGN,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,IACnCN,SAAS,GAAGM,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,EACtC,MAAM,cAAcO,UAAU,yCAC1BP,aAAa,CAAC,CAAC,CAAC,gBAChBM,UAAU,yCACVN,aAAa,CAAC,CAAC,CAAC,eAChBN,SAAS,yCAAyCM,aAAa,CAAC,CAAC,CAAC,EAAE,CAAC;EAC7E,MAAMgB,aAAa,GAAGT,UAAU,GAAGP,aAAa,CAAC,CAAC,CAAC;EACnD,MAAMiB,aAAa,GAAGX,UAAU,GAAGN,aAAa,CAAC,CAAC,CAAC;EACnD,MAAMQ,aAAa,GAAGd,SAAS,GAAGM,aAAa,CAAC,CAAC,CAAC;EAClD,MAAMP,YAAY,GAAGM,aAAa,CAAC,CAAC,CAAC;EACrC,MAAMU,YAAY,GAAGV,aAAa,CAAC,CAAC,CAAC;EACrC,MAAMmB,aAAa,GAAGH,yBAAyB,GAC3C;;;kDAG4CX,UAAU;kDACVC,UAAU;;;;;mDAMlDE,UAAU,2BAA2BP,aAAa,CAAC,CAAC,CAAC;qDAErDM,UAAU,2BAA2BN,aAAa,CAAC,CAAC,CAAC;cACjDY,sBAAsB,CAACnC,UAAU,CAAC;;;;mDAKtCiB,SAAS,2BAA2BM,aAAa,CAAC,CAAC,CAAC;yDAEpDK,UAAU,2BAA2BL,aAAa,CAAC,CAAC,CAAC;;;;;;4BAMnCN,SAAS;;;;mCAIFe,YAAY;8BACjBf,SAAS;wCACCe,YAAY;6DACST,aAAa,CAAC,CAAC,CAAC;;8CAE/BP,YAAY;4BAEhDhB,UAAU,GACN,oCAAoCuB,aAAa,CAAC,CAAC,CAAC,IAAI,GACxD,iCAAiCA,aAAa,CAAC,CAAC,CAAC,OAAO;gDACtBS,YAAY;;;;;;;;0CAQlBhB,YAAY;4DACMO,aAAa,CAAC,CAAC,CAAC;4CAChCS,YAAY;8DACMT,aAAa,CAAC,CAAC,CAAC;;;;OAIvE,GACD;mCAC6BP,YAAY;mCACZgB,YAAY;;sCAEThB,YAAY;sCACZgB,YAAY;8CACJL,UAAU;;oCAEpBY,aAAa;oCACbC,aAAa;oCACbT,aAAa;;;;wCAITQ,aAAa;0CACXC,aAAa;;;UAG7CL,sBAAsB,CAACnC,UAAU,CAAC;;;;;wCAKJ+B,aAAa;0CACXC,YAAY;;;;;;;;wBAQ9Bf,SAAS;;;;+BAIFe,YAAY;0BACjBf,SAAS;oCACCe,YAAY;;;;0CAINhB,YAAY;UAC5CoB,uBAAuB,CAACpC,UAAU,CAAC;4CACDgC,YAAY;;;;;;;;;;sCAUlBhB,YAAY;wCACVgB,YAAY;;;;;GAKjD;EAED,OAAO;gDACuCH,UAAU,MAAMC,UAAU;gDAC1BF,UAAU,MAAMX,SAAS;;MAEnEtB,IAAI,EAAE;oBACQ6B,MAAM,GAAG,GAAG,GAAG,iBAAiB;qBAE9CA,MAAM,IAAI,CAACE,cAAc,GAAG,OAAO,GAAG,4BAA4B;qBAElEF,MAAM,IAAI,CAACE,cAAc,GAAG,OAAO,GAAG,4BAA4B;uBAElEF,MAAM,GAAG,GAAGS,IAAI,CAACC,IAAI,CAACT,eAAe,GAAGR,SAAS,CAAC,EAAE,GAC3C,6BAA6BA,SAAS,MAAM;qBACtCO,MAAM,GAAG,qBAAqBC,eAAe,EAAE,GAAG,GAAG;;mCAEvCO,YAAY,MAAMhB,YAAY;;;0CAGvBA,YAAY;4CACVgB,YAAY;;;;QAIhDS,aAAa;;GAElB;AACH;AAEA,MAAMC,kBAAkB,GAAI7B,SAAkB,IAAI;EAChD,OAAOA,SAAS,GAAG;;;;;GAKlB,GACkB;;;;;GAKlB;AACH,CAAC;AAED,OAAM,SAAU8B,6BAA6BA,CACzCpB,aAAuC,EAAEvB,UAAU,GAAG,KAAK;EAC7DT,IAAI,CAACe,MAAM,CACPiB,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,IAAIA,aAAa,CAAC,CAAC,CAAC,KAAK,CAAC,EAChD,MAAM,iDAAiDA,aAAa,GAAG,CAAC;EAC5E,MAAMqB,QAAQ,GAAGrB,aAAa,CAAC,CAAC,CAAC,GAAG,CAAC;EACrC,OAAO;gDACuCA,aAAa,CAAC,CAAC,CAAC;;MAE1D5B,IAAI,EAAE;;;;;iDAKqCiD,QAAQ;;;;;;;;;;yBAUhCA,QAAQ;uCACMF,kBAAkB,CAAC1C,UAAU,CAAC;;;;8BAIvC4C,QAAQ,GAAG,CAAC;2BACfA,QAAQ;;;;;;;;;;;;;;;GAehC;AACH;AAEA,OAAM,MAAOC,mBAAmB;EAuB9BC,YACIC,MAAgC,EAAEC,WAAqC,EACvEhD,UAAU,GAAG,KAAK,EAAEC,UAAU,GAAG,KAAK,EAAEgD,IAAA,GAAmB,IAAI,EAC/DtC,UAAA,GAAsC,IAAI,EAC1CuC,sBAAA,GAAqC,IAAI,EACzCZ,yBAAyB,GAAG,KAAK;IAvBrC,KAAAa,aAAa,GAAG,CAAC,GAAG,EAAE,GAAG,CAAC;IAC1B,KAAAC,QAAQ,GAAG,mDAAmD;IAuB5D,IAAI,CAACJ,WAAW,GAAGA,WAAW;IAC9B,IAAI,CAACK,cAAc,GAAG;MAACC,CAAC,EAAE,CAAC,CAAC,CAAC;MAAEC,CAAC,EAAE,CAAC,CAAC,CAAC;MAAEC,CAAC,EAAE,CAAC,CAAC;IAAC,CAAC;IAC9C,MAAMC,QAAQ,GAAGzD,UAAU,GAAG+C,MAAM,CAAC,CAAC,CAAC,GAAGA,MAAM,CAAC,CAAC,CAAC;IACnD,IAAI,CAACW,MAAM,GAAG,CAAED,QAAQ,GAAG,CAAC,KAAK,CAAC,IAAI,CAACzD,UAAU,IACjCgD,WAAW,CAAC,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,IAAIhD,UAAW,KACnDgD,WAAW,CAAC,CAAC,CAAC,GAAG,CAAC,KAAK,CAAC,IAAI,CAAC/C,UAAU;IAC3C,IAAI,CAAC0D,eAAe,GAAG,IAAI,CAACD,MAAM,GAAG,CAAC,GAAG,CAAC;IAC1C,IAAI,CAACE,SAAS,GAAGZ,WAAW,CAAC,CAAC,CAAC,KAAK,CAAC,IAAI,CAAChD,UAAU;IAEpD,IAAI,CAAC,IAAI,CAAC0D,MAAM,IAAI,IAAI,CAACE,SAAS,EAAE;MAClC;MACA,IAAI,CAACC,iBAAiB,GAAG,CAAC,CAAC,EAAE,CAAC,EAAE,CAAC,CAAC;MAClC,IAAI,CAACtC,aAAa,GAAG,CAAC,EAAE,EAAE,CAAC,EAAE,CAAC,CAAC;KAChC,MAAM;MACL,MAAMuC,aAAa,GAAGhE,6BAA6B,CAC/CkD,WAAW,CAAC,CAAC,CAAC,EAAES,QAAQ,EAAET,WAAW,CAAC,CAAC,CAAC,EAAEhD,UAAU,CAAC;MACzD,IAAI,CAACuB,aAAa,GAAGuC,aAAa,CAACvC,aAAa;MAChD,IAAI,CAACsC,iBAAiB,GAAGC,aAAa,CAACD,iBAAiB;;IAG1D,IAAI,CAACE,QAAQ,GAAGlE,eAAe,CAC3B,IAAI,CAACwD,cAAc,EAAE,IAAI,CAACL,WAAW,EAAE,IAAI,CAACzB,aAAa,EACzD,IAAI,CAACsC,iBAAiB,CAAC;IAE3B,MAAMG,OAAO,GAAGf,IAAI,IAAI,IAAI;IAC5B,MAAMgB,yBAAyB,GAAGf,sBAAsB,IAAI,IAAI;IAChE,IAAIc,OAAO,EAAE;MACX,IAAI,CAACb,aAAa,CAACe,IAAI,CAAC,MAAM,CAAC;;IAGjC,IAAID,yBAAyB,EAAE;MAC7B,IAAI,CAACd,aAAa,CAACe,IAAI,CAAC,wBAAwB,CAAC;;IAGnD,IAAI,CAAC5B,yBAAyB,GAAGA,yBAAyB;IAC1D,IAAI,CAACtC,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAACC,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAAC+D,OAAO,GAAGA,OAAO;IACtB,IAAI,CAACrD,UAAU,GAAGA,UAAU;IAC5B,IAAI,CAACsD,yBAAyB,GAAGA,yBAAyB;IAC1D,CAAC,IAAI,CAAC/D,SAAS,EAAE,IAAI,CAACC,SAAS,EAAE,IAAI,CAACC,QAAQ,CAAC,GAC3C,IAAI,CAAC+D,WAAW,CAACnB,WAAW,CAAC,CAAC,CAAC,EAAEA,WAAW,CAAC,CAAC,CAAC,EAAES,QAAQ,CAAC;IAC9D,IAAI,CAACW,SAAS,GAAG,gBAAgB,IAAI,CAACP,iBAAiB,IAAI7D,UAAU,IACjEC,UAAU,IAAI,IAAI,CAACU,UAAU,IAAI,IAAI,CAACT,SAAS,IAAI,IAAI,CAACC,SAAS,IACjE,IAAI,CAACC,QAAQ,IAAI,IAAI,CAACsD,MAAM,IAAI,IAAI,CAACE,SAAS,IAC9C,IAAI,CAACtB,yBAAyB,EAAE;EACtC;EAEA6B,WAAWA,CAACE,SAAiB,EAAEC,SAAiB,EAAEb,QAAgB;IAEhE,MAAM9B,UAAU,GAAG,IAAI,CAACJ,aAAa,CAAC,CAAC,CAAC,GAAG,IAAI,CAACsC,iBAAiB,CAAC,CAAC,CAAC;IACpE,MAAMjC,UAAU,GAAG,IAAI,CAACL,aAAa,CAAC,CAAC,CAAC,GAAG,IAAI,CAACsC,iBAAiB,CAAC,CAAC,CAAC;IAEpE,IAAI,CAAC,IAAI,CAACH,MAAM,IAAI,IAAI,CAACE,SAAS,EAAE;MAClC;MACA,IAAI,CAAC3C,SAAS,GAAG,IAAI,CAACM,aAAa,CAAC,CAAC,CAAC,GAAG,CAAC;KAC3C,MAAM;MACL,IAAI,CAACN,SAAS,GAAGW,UAAU;;IAG7B,MAAM1B,SAAS,GAAGmE,SAAS,GAAG1C,UAAU,KAAK,CAAC;IAC9C,MAAMxB,SAAS,GAAGmE,SAAS,GAAG1C,UAAU,KAAK,CAAC;IAC9C,MAAMxB,QAAQ,GAAGqD,QAAQ,GAAG,IAAI,CAACxC,SAAS,KAAK,CAAC;IAChD,OAAO,CAACf,SAAS,EAAEC,SAAS,EAAEC,QAAQ,CAAC;EACzC;EAEAmE,WAAWA,CAAA;IACT,MAAMC,QAAQ,GAAG;QAEbhF,mBAAmB,CACf,IAAI,CAACmB,UAAU,EAAE,IAAI,CAACsD,yBAAyB,EAAE,IAAI,CAACP,MAAM,CAAC;QAEjEjD,uBAAuB,CACnB,IAAI,CAACuD,OAAO,EAAE,IAAI,CAACrD,UAAU,EAC7B,KAAK,CAAC,2DACN,IAAI,CAACV,UAAU,EAAE,IAAI,CAACC,SAAS,EAAE,IAAI,CAACC,SAAS,EAAE,IAAI,CAACC,QAAQ,EAC9D,IAAI,CAACsD,MAAM,GAAG,CAAC,GAAG,CAAC,CAAC;QAExB,IAAI,CAACA,MAAM,GACPrC,0BAA0B,CACtB,IAAI,CAACwC,iBAAiB,EAAE,IAAI,CAACtC,aAAa,EAAE,IAAI,CAACvB,UAAU,EAC3D,IAAI,CAACiB,SAAS,EAAE,KAAK,EAAE,IAAI,EAAE,IAAI,CAAC,GACrC,IAAI,CAAC2C,SAAS,GAAGjB,6BAA6B,CACzB,IAAI,CAACpB,aAAa,EAAE,IAAI,CAACvB,UAAU,CAAC,GACxCqC,sBAAsB,CAClB,IAAI,CAACwB,iBAAiB,EAAE,IAAI,CAACtC,aAAa,EAC1C,IAAI,CAACvB,UAAU,EAAE,IAAI,CAACiB,SAAS,EAAE,KAAK,EAAE,IAAI,EAC5C,IAAI,CAACqB,yBAAyB,EAAE,IAAI,CAAE;KACnE;IACD,OAAOkC,QAAQ;EACjB","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}